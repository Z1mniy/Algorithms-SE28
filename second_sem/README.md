# Алгоритмы на графах

## Реализация структур хранения графа

- Список смежности

> Сложность по памяти: $O(V$ + сумма степеней всех вершин$)$ $= O(V + 2xE) = O(V + E)$

- Матрица смежности - это самый популярный и расточительный способ представления графа в памяти. Его уместно использовать, если граф плотный, т.е $E={\frac {V(V-1)}{2}}$.

> Сложность по памяти: $O(V^2)$

- Список ребер

> Сложность по памяти: $O(E)$

- Матрица инцидентности - не самый частый вариант хранения за счет затрат по памяти, в основном используют в прикладных задачах (телеком), а также любят в теории

> Сложность по памяти: $O(V × E)$
-----

## Обход в глубину DFS

### Принцип работы
Обход в глубину, или DFS (англ. depth-first search), в чём-то похож на действия, выполняемые человеком для прохождения лабиринта (DFS собственно и является алгоритмом для решения лабиринтов). Находясь на очередной развилке, мы ставим метку, обозначающую, что мы уже здесь были, после чего идём в произвольном ещё не посещённом направлении. На следующей развилке мы выполняем те же действия, и так пока не попадём на развилку, которая не открывает нам ни одного нового пути (все уже посещены). В таком случае мы возвращаемся на предыдущую развилку и, если там ещё остались непосещённые направления, идём туда. Если же оттуда также некуда идти, то мы возвращаемся назад ещё на одну развилку, и так далее, пока не найдём непосещённое направление.

### Логика работы

- __рекурсивная реализация:__ выбирается начальная вершина, она помечается как посещенная. далее рекурсивно: для текущей вершины просмтариваются все соседние, если соседняя не посещена, рекурсивно вызывается DFS для неё. после обработки всех вершин, происходит backtracking.

- __итеративная реализация:__ используется стек для хранения вершин, вершина извлекается из стека, обрабатывается, а ее непосещенные соседи добавляются в стек.

- __инвариант:__ все посещенные вершины достижимы из стартовой

- __оптимизация:__ битовая маска visited, ранний выход

#### Псевдокод

```
function doDfs(G[n]: Graph): // функция принимает граф G с количеством вершин n и выполняет обход в глубину во всем графе 
   visited = array[n, false]  // создаём массив посещённых вершины длины n, заполненный false изначально
          
   function dfs(u: int):   
      visited[u] = true
      for v: (u, v) in G        
         if not visited[v]               
            dfs(v)

   for i = 1 to n             
      if not visited[i]                    
         dfs(i)
```

#### Пример рекурсивной реализации

```cpp
void dfsRecursive(int v, int from, const vector<vector<int>>& graph, vector<bool>& visited) {
    if (visited[v]) return;
    visited[v] = true;
    for (int to : graph[v]) {
        if (to == from) continue;
        dfsRecursive(to, v, graph, visited);
    }
}
```

#### Пример итеративной реализации

```cpp
void dfsIterative(const vector<vector<int>>& graph, int start) {
    vector<bool> visited(V, false);
    stack<int> stack;
    stack.push(start);
    
    while (!stack.empty()) {
        int v = stack.top();
        stack.pop();
        
        if (!visited[v]) {
            visited[v] = true;
            //можно добавить кастомную обработку вершины ...
            for (auto it = graph[v].rbegin(); it != graph[v].rend(); ++it) {
                if (!visited[*it]) {
                    stack.push(*it);
                }
            }
        }
    }
}
```

### Используемые структуры данных

- рекурсивная реализация использует стек вызовов
- итеративная реализация - явный стек
- массив/множество visited

### Асимптотика

|          |Список смежности|Матрица смежности|Список ребер|
|----------|--------------------|-----------------|------------|
|По времени|$O(V + E)$|$O(V^2)$|$O(V + E)$|
|По памяти|$O(V)$|$O(V^2)$|$O(V)$|


### Применимость

- Поиск компонент связности.
- Топологическая сортировка (DAG).
- Поиск циклов, мостов, точек сочленения.
- Генерация лабиринтов, решение головоломок.

------

## Обход в ширину BFS

### Принцип работы
Суть BFS достаточно проста. Обход начинается с посещения определённой вершины (для обхода всего графа часто выбирается произвольная вершина). Затем алгоритм посещает соседей этой вершины. За ними - соседей соседей, и так далее.

### Логика работы

- выбирается начальная вершина, она помечается как посещенная и добавляется в очередь. извлекается вершина из очереди, обрабатываются все ее соседи, если соседняя вершина не посещена, она помечается как посещенная и добавляется в очередь. процесс продолжается,ю пока очередь не станет пустой.
- __инвариант__: все вершины в очереди находятся на расстоянии `d` или `d+1` от стартовой
- __оптимизация__:

  - вусторонний BFS (Bidirectional BFS) – если известна целевая вершина, запускаем BFS одновременно из старта и цели.

  - Использование deque (если граф 0-1, как в алгоритме 0-1 BFS).

  - Сжатие координат (если вершины – точки на сетке).

  - Ранний выход (если нашли нужную вершину)

#### Псевдокод

- $source$ — исходная вершина
- $destination$ — конечная вершина
- $G$ — граф, состоящий из списка вершин V и списка смежности E. Вершины нумеруются целыми числами.
- $Q$ — очередь.
- В поле `d[u]` хранится расстояние от source до u.

```
int BFS(G: (V, E), source: int, destination: int):
    d = int[|V|]
    fill(d, ∞)
    d[source] = 0
    Q = ∅

    Q.push(source)
    while Q ≠∅
 
        u = Q.pop()
        for v: (u, v) in E
            if d[v] == ∞

                d[v] = d[u] + 1
                Q.push(v)
    return d[destination]
```

#### Пример кода

```cpp
void BFS(const vector<vector<int>>& graph, int start) {
 queue<int> q;
 vector<bool> visited(graph.size(), false);
 q.push(start);
 visited[start] = true;
 
 while (!q.empty()) {
  int v = q.front();
  q.pop();
  //...
  for (int neighbor : graph[v]) {
   if (!visited[neighbor]) {
    visited[neighbor] = true;
    q.push(neighbor);
   }
  }
 }
}
```

### Используемые структуры данных

- массив посещенных вершин
- очередь. всегда ее используем

### Асимптотика

|          |Список смежности|Матрица смежности|Список ребер|
|----------|--------------------|-----------------|------------|
|По времени|$O(V + E)$|$O(V^2)$|$O(V + E)$|
|По памяти|$O(V)$|$O(V^2)$|$O(V)$|

### Корректность алгоритма
__Утверждение:__ В очереди поиска в ширину расстояние вершин до s
 монотонно неубывает.  
__*Докозательство*__
>Докажем это утверждение индукцией по числу выполненных алгоритмом шагов.
Введем дополнительный инвариант: у любых двух вершин из очереди, расстояние до s
 отличается не более чем на 1.  
__База__: изначально очередь содержит только одну вершину s.  
__Переход__: пусть после i−й итерации в очереди a+1 вершин с расстоянием x и b вершин с расстоянием x+1.  
__Рассмотрим i−ю итерацию.__ Из очереди достаем вершину v, с расстоянием x. Пусть у v есть r непосещенных смежных вершин. Тогда, после их добавления, в очереди находится a вершин с расстоянием x и, после них, b+r вершин с расстоянием x+1.  
Оба инварианта сохранились, ⇒ после любого шага алгоритма элементы в очереди неубывают.

__Теорема:__ Алгоритм поиска в ширину в невзвешенном графе находит длины кратчайших путей до всех достижимых вершин.  
__*Докозательство*__
>Допустим, что это не так. Выберем из вершин, для которых кратчайшие пути от $s$ найдены некорректно, ту, настоящее расстояние до которой минимально. Пусть это вершина $u$, и она имеет своим предком в дереве обхода в ширину $v$, а предок в кратчайшем пути до $u$ — вершина $w$.  
Так как $w$ — предок u в кратчайшем пути, то $ρ(s,u)=ρ(s,w)+1>ρ(s,w)$, и расстояние до w найдено верно, $ρ(s,w)=d[w]$. Значит, $ρ(s,u)=d[w]+1$.  
Так как $v$ — предок u в дереве обхода в ширину, то $d[u]=d[v]+1$.  
Расстояние до $u$ найдено некорректно, поэтому $ρ(s,u)<d[u]$. Подставляя сюда два последних равенства, получаем $d[w]+1<d[v]+1$, то есть, $d[w]<d[v]$. Из ранее доказанной леммы следует, что в этом случае вершина $w$ попала в очередь и была обработана раньше, чем $v$. Но она соединена с $u$, значит, $v$ не может быть предком $u$ в дереве обхода в ширину, мы пришли к противоречию, следовательно, найденные расстояния до всех вершин являются кратчайшими.

### Применимость

- поиск кратчайшего пути в невзвешенном графе
- проверка на двудольность
- поиск компонент связности
- поиск ближайших соседей

### Ссылочки
[Нирк](https://neerc.ifmo.ru/wiki/index.php?title=%D0%9E%D0%B1%D1%85%D0%BE%D0%B4_%D0%B2_%D1%88%D0%B8%D1%80%D0%B8%D0%BD%D1%83)


-----

## Топологическая сортировка

### Чи шо вообще

Топологическая сортировка (англ. topological sort) ориентированного ациклического графа $G=(V,E)$ представляет собой упорядочивание вершин таким образом, что для любого ребра $(u,v)∈E(G)$ номер вершины $u$ меньше номера вершины $v$.

Задача топологической сортировки графа звучит так: дан ориентированный граф, и требуется найти такой порядок вершин, в котором все рёбра графа вели из более ранней вершины в более позднюю.

### Логика работы

- __DFS__ при завершении обхода вершины, добавляем ее в стек, затем его разворачиваем. (либо сразу в конец без стека)
- __алгоритм Кана__ считаем входные степени вершин, добавляем вершины с входной степенью 0 в очередь. удаляем вершины из очереди, уменьшаемм входные степени их соседей. если вершина с входной степенью 0 появилась - добавляем ее в очередь. повторяем, пока не обработаем все вершины.
- __инвариант__: вершина добавляется в порядок только после всех своих потомков (DFS); в очереди всегда находятся вершины с `in_degree = 0`, гарантируя корректный порядок (Kana).

#### Псевдокод

```
// G — исходный граф
function topologicalSort(): проверить граф G на ацикличность
    fill(visited,false)
    for v∈V(G)
        if not visited[v]
             dfs(v)
    ans.reverse()

function dfs(u):
    visited[u]=true
    for uv ∈ E(G)
        if not visited[v]
            dfs(v)
    ans.pushBack(u)
```

#### Топологическая сортировка

```cpp
void tSort(std::vector<std::vector<int>>& graph, int v, std::vector<int>& visited, std::vector<int>& order) {
    visited[v] = 1;
    for (int to : graph[v]) {
        if (visited[to] == 0) {
            tSort(graph, to, visited, order);
        }
    }
    order.push_back(v);
}
```

#### Алгоритм Кана

```cpp
vector<int> tSortKana(int v, vector<vector<int>>& edges) {
 vector<int> in_degree(V, 0);
 vector<vector<int>> adj(V);
 vector<int> result;
 
 for (const auto& edge : edges) {
  int u = edge[0], v = edge[1];
  adg[u].push_back(v);
  in_degree[v]++;
 }
 
 queue<int> q;
 for (int i = 0; i < V; ++i) {
  if (in_degree[i] == 0) {
   q.push(i);
  }
 }
 
 while (!q.empty()) {
  int node = q.front();
  q.pop();
  result.push_back(node);
  
  for (int neighbor : adj[node]) {
   in_degree[neighbor]--;
   if (in_degree[neighbor] == 0) {
    q.push(neighbor);
   }
  }
 }
 
 return result;
}
```

### Используемые структуры данных

- массив посещенных
- стек (DFS)
- очередь (алгоритм Кана)

### Асимптотика

|          |Список смежности|Матрица смежности|
|----------|--------------------|-----------------|
|По времени|$O(V + E)$|$O(V^2)$|
|По памяти|$O(V)$|$O(V)$|

### Корректность алгоритма
__Теорема:__ $G$ — ациклический ориентированный граф, тогда $∃ φ:V→\{1..n\},uv∈E⇒φ(u)<φ(v)$  
__*Докозательство*__
>Определим $leave[u]$ как порядковый номер окраски вершины $u$ в черный цвет в результате работы алгоритма dfs. Рассмотрим функцию $φ=n+1−leave[u]$. 

Очевидно, что такая функция подходит под критерий функции $φ$ из условия теоремы, если выполняется следующее утверждение:  
__Лемма:__ $G$ — ациклический ориентированный граф, тогда $uv∈E⇒leave[u]>leave[v]$
>Рассмотрим произвольное ребро $(u,v)$, исследуемое процедурой dfs. При исследовании вершина $v$ не может быть серой, так как серые вершины в процессе работы dfs всегда образуют простой путь в графе, и факт попадания в серую вершину $v$ означает, что в графе есть цикл из серых вершин, что противоречит условию утверждения. Следовательно, вершина $v$ должна быть белой либо черной. Если вершина $v$ — белая, то она становится потомком $u$, так что $leave[u]>leave[v]$. Если $v$ — черная, значит, работа с ней уже завершена и значение $leave[v]$ уже установлено. Поскольку мы все еще работаем с вершиной $u$, значение $leave[u]$ еще не определено, так что, когда это будет сделано, будет выполняться неравенство $leave[u]>leave[v]$. Следовательно, для любого ребра $(u,v)$ ориентированного ациклического графа выполняется условие $leave[u]>leave[v]$.

Таким образом, теорема доказана.

### Применимость

- планирование задач с зависимостями
- разрешение зависимостей в системах управления пакетами
- обход графа зависимостей в базах данных и анализе сетей

### Ссылочки
[Нирк](https://neerc.ifmo.ru/wiki/index.php?title=%D0%98%D1%81%D0%BF%D0%BE%D0%BB%D1%8C%D0%B7%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D0%B5_%D0%BE%D0%B1%D1%85%D0%BE%D0%B4%D0%B0_%D0%B2_%D0%B3%D0%BB%D1%83%D0%B1%D0%B8%D0%BD%D1%83_%D0%B4%D0%BB%D1%8F_%D1%82%D0%BE%D0%BF%D0%BE%D0%BB%D0%BE%D0%B3%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%BE%D0%B9_%D1%81%D0%BE%D1%80%D1%82%D0%B8%D1%80%D0%BE%D0%B2%D0%BA%D0%B8)

-----

## Конденсация графа + поиск комп слабой свзяности

### Чи шо вообще

__Конденсацией__ орграфа $G$ называют такой орграф $G'$, вершинами которого служат компоненты сильной связности $G$, а дуга в $G'$ присутствует только если существует хотя бы одно ребро между вершинами, входящими в соответствующие компоненты связности. Конденсация графа не содержит кратных ребер.

__Слабая связность__ - вершины связаны в неориентированой версии графа.

__Сильная связность__ - пары вершин - путь.

### Логика работы

- __поиск wcc через dfs/bfs__

    идем по всем вершинам. если вершина не посещена, запускаем один из обходов. обходим все ребра. все посещенные вершины относятся к одной компоненте. повторяем пока не покроем все вершины.

- __конденсация графа__ (scc + построение dag)

    для поиска scc используем алгоритм Косараджу или Тарьяна

    >Косараджу: основан на dfs и транспониировании графа. Требует два полных обхода графа (один для сортировки, второй для обхода транспонированного). Логика работы: запускаем обход и кладём вершины в стек по завершении обхода, меняем направления всех ребер. запускаем второй dfs на транспонированном графе, достаём из стека и запускаем обход, каждое новое дерево dfs - scc

    >Тарьяна: основан на 1 dfs с поддержкой времени входа и низкой связи. назначаем каждой вершине entry time (бесконечное время входа), если встречаем обратное ребро обновляем low-link. если entry[v]==low[v], то вершина - корень scc, достаем все вершины из стека, пока не достигнем v.

    __scc__ - множество вершин, из которых можно добраться друг до друга. каждая scc становится одной вершиной. если из одной scc есть путь в другую, добавляем ребро

#### Псевдокод

```
function dfs1(v):                                          
 color[v] = 1
 for (v, u) in E
  if not visited[u]
   dfs1(G[v][u])
 Добавляем вершину v в конец списка ord

function dfs2(v):                                          
 component[v] = col
 for (v, u) in E
  if (вершина u еще не находится ни в какой компоненте)                       
   dfs2(H[v][u])

function main():
 считываем исходные данные, формируем массивы G и H
 for u in V                           
  if not visited[u]
   dfs1(u)
 col = 1
 for (по всем вершинам u списка ord[] в обратном порядке)                                                        
  if (вершина u не находится ни в какой компоненте)
   dfs2(u)
   col++
```

#### Поиск компонент слабой связности

```cpp
void dfs(int v, vector<vector<int>>& adj, vector<bool>& visited) {...}


int WCC(int V, vector<pair<int, int>>& edges) {
 vector<vector<int>> adj(V);
 vector<bool> visited(V, false);
 
 for (auto& edge : edges) {
  adj[edge.first].push_back(edge.second);
  adj[edge.second].push_back(edge.first);
 }
 
 int components = 0;
 for (int i = 0; i < V; ++i) {
  if (!visited[i]) {
    dfs(i, adj, visited);
    components++:
  }
 }
 return components;
}
```

#### Поиск компонент сильной связности Косораджу

```cpp
void dfs1(int v, vector<vector<int>>& agj, vector<bool>& visited, stack<int>& order) {...}
void dfs2(int v, vector<vector<int>>& reverse_adj, vector<bool>& visited, vector<int>& component) {...}


vector<vector<int>> findSCC(int V, vector<pair<int, int>>& edges) {
 vector<vector<int>> adj(V), reverse_adj(V);
 vector<bool> visited(V, false);
 stack<int> order;
 
 for (auto& edge : edges) {
  adj[edge.first].push_back(edge.second);
  reverse_adj[edge.second].push_back(edge.first);
 }
 
 for (int i = 0; i < V; ++i) {
  if (!visited[i]) dfs1(i, adj, visited, order);
 }
 
 fill(visited.begin(), visited.end(), false);
 vector<vector<int>> sccs;
 while (!order.empty()) {
  int v = order.top();
  order.pop();
  if (!visited[v]) {
   vector<int> component;
   dfs2(v, reverse_adj, visited, component);
   sccs.push_back(component);
  }
 }
 return sccs;
}
```

### Используемые структуры данных

- орграф и неориентированный граф
- список смежности
- матрица смежности
- очередь или стек для обхода
- __DSU(Union-Find)__ - для эффективного объединения компонент.

    это структура данныз, которая поддерживает динамическое объединение множеств и поиск представителя множества.

    без оптимизации работает за $O(n)$, с оптимизацией за $O( \alpha n)$ используется сжатие пути + ранг(глубина)

    подходит только для динамических непересекающихся множеств. не дает прямой информации о количестве элементов в каждом множестве. очень быстрая работа почти за $O(1)$

### Асимптотика

|          |Поиск компонент слабой связности с использование DFS/BFS|Поиск компонент слабой связности Union-find|Конденсация графа с использованием Косарайю/Тарьяна|
|----------|--------------------|-----------------|------------|
|По времени|$O(V + E)$|$O(\alpha(V))$|$O(V + E)$|

### Корректность алгоритма
__Лемма:__ Запустим dfs. Пусть A и B — две различные компоненты сильной связности, и пусть в графе конденсации между ними есть ребро A→B. Тогда $$\max_{a \in A} (t_{\mathrm{out}_a}) > \max_{b \in B} (t_{\mathrm{out}_b})$$
__*Доказательство*__. Рассмотрим два случая, в зависимости от того, в какую из компонент dfs зайдёт первым.

>Пусть первой была достигнута компонента $A$, то есть в какой-то момент времени dfs заходит в некоторую вершину $v$ компоненты $A$, и при этом все остальные вершины компонент $A$ и $B$ ещё не посещены. Но так как по условию в графе конденсаций есть ребро $A→B$, то из вершины $v$ будет достижима не только вся компонента $A$, но и вся компонента $B$. Это означает, что при запуске из вершины $v$ обход в глубину пройдёт по всем вершинам компонент $A$ и $B$, а, значит, они станут потомками по отношению к $v$ в дереве обхода, и для любой вершины $u∈A∪B$,$u≠v$ будет выполнено $tout_v>tout_u$ , что и утверждалось.

>Второй случай проще: из $B$ по условию нельзя дойти до $A$, а значит, если первой была достигнута $B$, то dfs выйдет из всех её вершин ещё до того, как войти в $A$.

### Применимость

- анализ сетей (группировка узлов)
- разбиение зависимостей
- моделирование

### Ссылочки
[Алгокод вики](https://wiki.algocode.ru/index.php?title=%D0%9A%D0%BE%D0%BD%D0%B4%D0%B5%D0%BD%D1%81%D0%B0%D1%86%D0%B8%D1%8F_%D0%B3%D1%80%D0%B0%D1%84%D0%B0)

----

## Поиск и восстановление всех видов циклов

### Логика работы

- используем один из обходов. при обходе сохраняем текущий путь, если обнаруживается вершина, которая уже находится в текущем пути, значит мы нашли цикл. цикл восстановляется из текущего пути.

```cpp
void findCyclesDFS(int v, int parent, const vector<vector<int>>& graph, vector<bool>& visited, vector<int>& path, vector<vector<int>>& cycles) {
    visited[v] = true;
    path.push_back(v);

    for (int neighbor : graph[v]) {
        if (!visited[neighbor]) {
            findCyclesDFS(neighbor, v, graph, visited, path, cycles);
        } else if (neighbor != parent) {
            vector<int> cycle;
            int start = neighbor;
            int i = path.size() - 1;
            while (path[i] != start) {
                cycle.push_back(path[i]);
                i--;
            }
            cycle.push_back(start);
            cycles.push_back(cycle);
        }
    }

    path.pop_back();
}
```

### Используемые структуры данных

- стек, список смежности, матрица смежности, очередь

### Асимптотика

|          |Нахождение цикла|Востановление циклов ($C$ - кол-во циклов для востановления )|
|----------|--------------------|-----------------|
|По времени|$O(V + E)$|$O(C*(V + E))$|

### Корректность алгоритма

>Пусть дан граф $G$. Запустим $dfs(G)$. Рассмотрим выполнение процедуры поиска в глубину от некоторой вершины $v$. Так как все серые вершины лежат в стеке рекурсии, то для них вершина $v$ достижима, так как между соседними вершинами в стеке есть ребро. Тогда, если из рассматриваемой вершины $v$ существует ребро в серую вершину $u$, то это значит, что из вершины $u$ существует путь в $v$ и из вершины $v$ существует путь в $u$ состоящий из одного ребра. И так как оба эти пути не пересекаются, то цикл существует.

>Докажем, что если в графе $G$ существует цикл, то $dfs(G)$ его всегда найдет. Пусть $v$ — первая вершина принадлежащая циклу, рассмотренная поиском в глубину. Тогда существует вершина $u$, принадлежащая циклу и имеющая ребро в вершину $v$. Так как из вершины $v$ в вершину $u$ существует белый путь (они лежат на одном цикле), то по лемме о белых путях во время выполнения процедуры поиска в глубину от вершины $u$, вершина $v$ будет серой. Так как из $u$ есть ребро в $v$, то это ребро в серую вершину. Следовательно $dfs(G)$ нашел цикл.

### Применимость

- анализ в многопоточных программах

### Ссылочки
[Нирк](https://neerc.ifmo.ru/wiki/index.php?title=%D0%98%D1%81%D0%BF%D0%BE%D0%BB%D1%8C%D0%B7%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D0%B5_%D0%BE%D0%B1%D1%85%D0%BE%D0%B4%D0%B0_%D0%B2_%D0%B3%D0%BB%D1%83%D0%B1%D0%B8%D0%BD%D1%83_%D0%B4%D0%BB%D1%8F_%D0%BF%D0%BE%D0%B8%D1%81%D0%BA%D0%B0_%D1%86%D0%B8%D0%BA%D0%BB%D0%B0)

----

## Поиск Гамильтонова цикла при выполнении достаточных условий

### Чи шо вообще

Замкнутый простой путь, проходящий через каждую вершину графа ровно один раз.

Достаточные условия Дирака и Оре

__Теорема Дирака__
>Если $n⩾3$ и $deg v⩾n/2$ для любой вершины $v$ неориентированного графа $G$, то $G$ — гамильтонов граф.

__Теорема Оре__
>Если $n⩾3$ и $deg u+deg v⩾n$ для любых двух различных несмежных вершин $u$ и $v$ неориентированного графа $G$, то $G$ — гамильтонов граф.

### Логика работы

- выбирается начальная вершина, рекурсивно: для текущей вершины проверяются все непосещенные соседи, если она не посещена, она добавляется в текущий путь. если путь содержит все вершины и есть ребро обратно в начальную вершину, найден гамильтов цикл

#### Псевдокод

```
function findHamiltonianCycle(⟨V,E⟩):
 for v∈V:                                          // Добавляем все вершины графа в очередь
 queue.pushBack(v)
 for k = 0..n * (n - 1)
 if (queue.at(0), queue.at(1)) ∉ E // Проверяем существования ребра между первой и второй вершинами очереди
  i = 2                                             
  while (queue.at(0), queue.at(i)) ∉ E or (queue.at(1), queue.at(i + 1)) ∉E
   i++                                         // Ищем индекс удовлетворяющую условию вершины
  queue.swapSubQueue(1, i)                        // Разворачиваем часть перестановки от 1-й до найденной позиции включительно
 queue.pushBack(queue.top())
 queue.pop()
```

#### Пример кода

```cpp
bool isSafe(int v, const vector<vector<int>>& graph, const vector<int>& path, int pos) {
    if (graph[path[pos - 1]][v] == 0) {
        return false;
    }
    for (int i = 0; i < pos; ++i) {
        if (path[i] == v) {
            return false;
        }
    }

    return true;
}

bool hamiltonianCycleUtil(const vector<vector<int>>& graph, vector<int>& path, int pos) {
    int n = graph.size();
    if (pos == n) {
        if (graph[path[pos - 1]][path[0]] == 1) {
            return true;
        } else {
            return false;
        }
    }

    for (int v = 1; v < n; ++v) {
        if (isSafe(v, graph, path, pos)) {
            path[pos] = v;
            if (hamiltonianCycleUtil(graph, path, pos + 1)) {
                return true;
            }
            path[pos] = -1;
        }
    }

    return false;
}
```

### Используемые структуры данных

- список смежности, матрица смежности

### Асимптотика

|          |Стандартный случай|Худший случай|
|----------|--------------------|-----------|
|По времени|$O(n^2)$|$O(n!)$|
|По памяти|$O(V)$|$O(V)$|

### Корректность алгоритма

Алгоритм находит гамильтонов цикл корректно и это следует из следующих двух лемм

__Лемма:__ Каждый раз, когда нам надо искать вершину $v_i$, где $i>2$, такую что $v_1v_i,v_2v_{i+1}∈E$, такая вершина действительно существует.

>Рассмотрим множество $S=\{i∣v_1v_i∈E\}$, состоящее из индексов вершин, смежных с $v_1$, и множество $T=\{i+1∣v_2v_{i+1}∈E\}$, индексов вершин смежных с $v_2$. Заметим, что $S⊂\{3,4,…,n\}$, а $T⊂\{2,3,…,n−1\}$, тогда $S∪T⊂\{2,3,…,n\}$, а значит $|S∪T|⩽n−1$, в то же время $|S|+|T|=degv1+degv2⩾n$ (по условию теоремы Оре или теоремы Дирака). Из этого следует, что $S∩T≠∅$, а это и значит, что искомая вершина существует.

__Лемма:__ После $n(n−1)$ итераций между каждой парой соседних вершин очереди существует ребро.
>Достаточно заметить, что каждую итерацию алгоритма, мы, в случае отсутствия ребра, между $v_1$ и $v_2$ увеличиваем количество пар соседних в очереди вершин, между которыми есть ребро, как минимум на $1$ (это прямое следствие условия поиска нужной вершины, в случае отсутствия ребра), для поиска такой пары требуется не более $n$ итераций. Таких пар изначально не более $n$, откуда следует, что после $n$ итераций, второе условие будет выполнено.

### Применимость

- поиск оптимальных маршрутов
- анализ сетей


### Ссылочки
[Нирк](https://neerc.ifmo.ru/wiki/index.php?title=%D0%90%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC_%D0%BD%D0%B0%D1%85%D0%BE%D0%B6%D0%B4%D0%B5%D0%BD%D0%B8%D1%8F_%D0%93%D0%B0%D0%BC%D0%B8%D0%BB%D1%8C%D1%82%D0%BE%D0%BD%D0%BE%D0%B2%D0%B0_%D1%86%D0%B8%D0%BA%D0%BB%D0%B0_%D0%B2_%D1%83%D1%81%D0%BB%D0%BE%D0%B2%D0%B8%D1%8F%D1%85_%D1%82%D0%B5%D0%BE%D1%80%D0%B5%D0%BC_%D0%94%D0%B8%D1%80%D0%B0%D0%BA%D0%B0_%D0%B8_%D0%9E%D1%80%D0%B5)

----

## Поиск Эйлерова цикла

### Чи шо вообще

Замкнутый путь, который проходит по каждому ребру, причем ровно один раз.

#### Критерий Эйлеровости
Для того, чтобы граф $G=(V,E)$
 был эйлеровым необходимо чтобы:
1. Все вершины имели четную степень.
2. Все компоненты связности, кроме, может быть, одной, не содержали ребер.

### Логика работы

- используем DFS, ребра удаляются после их посещения, вершины добавляются в цикл в порядке их завершения
#### Псевдокод
```
boolean checkForEulerPath():
   int OddVertex =0
   for v:v ∈ V
       if deg(v) mod 2==1
           OddVertex++
   if OddVertex >2 // если количество вершин с нечетной степенью больше двух, то граф не является эйлеровым
       return false
   boolean visited(|V|, false) // массив инициализируется значениями false
   for v:v ∈ V
       if deg(v) >0
           dfs(v, visited)
           break
   for v:v ∈ V
       if deg(v) >0 and not visited[v]   // если количество компонент связности, содержащие ребра, больше одной,
           return false              // то граф не является эйлеровым
   return true   // граф является эйлеровым
```

#### Пример кода
```cpp
void eulerianCycleUtil(int v, vector<vector<int>>& graph, vector<int>& cycle) {
    while (!graph[v].empty()) {
        int u = graph[v].back();
        graph[v].pop_back();
        eulerianCycleUtil(u, graph, cycle);
    }
    cycle.push_back(v);
}

vector<int> findEulerianCycle(vector<vector<int>>& graph, int numVertices) {
    vector<int> cycle;
    for (int i = 0; i < numVertices; ++i) {
        if (graph[i].size() % 2 != 0) {
            cout << "Эйлеров цикл не существует" << endl;
            return {};
        }
    }
    eulerianCycleUtil(0, graph, cycle);
    for (int i = 0; i < numVertices; ++i) {
        if (!graph[i].empty()) {
            cout << "Эйлеров цикл не существует" << endl;
            return {};
        }
    }
    reverse(cycle.begin(), cycle.end());
    return cycle;
}
```

#### Рекурсивная реализация за $O(E)$
```
function euler(u):
   while (first[u] < g[u].size()):  //если first[u] = g[u].size, рёбра во все смежные вершины уже посещены
      i,v = g[u][first[u]]
      first[u] += 1
      if (!vis[i]):
         vis[i] = true
         euler(v)
         print(v)
```

### Используемые структуры данных

- список смежности, матрица смежности

### Асимптотика

|          |Поиск Эйлерового цикла|
|----------|--------------------|
|По времени|$O(V + E)$|
|По памяти|$O(V + E)$|

### Корректность алгоритма

### Применимость

- поиск оптимальных маршрутов
- анализ сетей

------

## Нахождение компонент связности в неориентированном графе

### Чи шо вообще

Набор вершин графа, между любой парой которых существует путь

### Логика работы

- создаем массив доля хранения посещенных вершин, при обходе для каждой непосещенной вершины запускаем обход, ве вершины, достижимые из текущей будут включены в одному компоненту связности. повторяем процесс, пока все вершины не будут посещены.

```cpp
void dfs(int v, const vector<vector<int>>& graph, vector<bool>& visited, vector<int>& component) {
    visited[v] = true;
    component.push_back(v);

    for (int neighbor : graph[v]) {
        if (!visited[neighbor]) {
            dfs(neighbor, graph, visited, component);
        }
    }
}

vector<vector<int>> findConnectedComponents(const vector<vector<int>>& graph, int numVertices) {
    vector<bool> visited(numVertices, false);
    vector<vector<int>> components;

    for (int i = 0; i < numVertices; ++i) {
        if (!visited[i]) {
            vector<int> component;
            dfs(i, graph, visited, component);
            components.push_back(component);
        }
    }

    return components;
}
```

### Используемые структуры данных

- список смежности, матрица смежности

### Асимптотика

|          |Поиск комопонент связности|
|----------|--------------------|
|По времени|$O(V + E)$|
|По памяти|$O(V)$|

### Корректность алгоритма

### Применимость

- анализ графов (электрические цепи, транспортные сети)

-----

## Алгоритмы Краскала

### Логика работы

- сортируем ребра по возрастанию. Каждая вершина графа будет представлять собой отдельное множество. далее обход ребер: для каждого ребра проверяется, принадлежат ли его вершины разным множества, если да, то ребро добавляется в остовое дерева, а множества объединяются, если нет, то ребро пропускается (иначе мы получим цикл). процесс продолжает пока не обработаны все ребра или пока не будет найдено V - 1 ребро.
- __инвариант__: на каждом шаге алгоритма множество выбранных ребер образует лес(набор деревьев) и каждое новое ребро добавляется так, чтобы не образовывать циклов
- __оптимизация__: сортировка ребер, ранняя остановка (V - 1 ребро), параллельная обработка (несколько потоков обработки)

```cpp
struct Edge {
    int src, dest, weight;
};

class DSU {
    vector<int> parent, rank;

public:
    DSU(int n) {
        parent.resize(n);
        rank.resize(n, 0);
        for (int i = 0; i < n; ++i) {
            parent[i] = i;
        }
    }
    
    int find(int u) {
        if (parent[u] != u) {
            parent[u] = find(parent[u]);
        }
        return parent[u];
    }

    void unite(int u, int v) {
        int rootU = find(u);
        int rootV = find(v);

        if (rootU != rootV) {
            if (rank[rootU] > rank[rootV]) {
                parent[rootV] = rootU;
            } else if (rank[rootU] < rank[rootV]) {
                parent[rootU] = rootV;
            } else {
                parent[rootV] = rootU;
                rank[rootU]++;
            }
        }
    }
};

bool compareEdges(const Edge& a, const Edge& b) {
    return a.weight < b.weight;
}

vector<Edge> kruskalMST(vector<Edge>& edges, int numVertices) {
    sort(edges.begin(), edges.end(), compareEdges);

    DSU dsu(numVertices);
    vector<Edge> mst;

    for (const Edge& edge : edges) {
        int u = edge.src;
        int v = edge.dest;
        if (dsu.find(u) != dsu.find(v)) {
            mst.push_back(edge);
            dsu.unite(u, v);
        }
    }

    return mst;
}
```

### Используемые структуры данных

- список ребер
- система непересекающихся множеств

### Асимптотика

|          |Краскал|
|----------|--------------------|
|По времени|$O(ElogE)$|
|По памяти|$O(V + E)$|

### Корректность алгоритма

### Применимость

- поиск MST
- решение задач с минимизацией суммарного веса ребер

----

## Алгоритм Прима

### Логика работы

1. Инициализация:
    - Выбираем произвольную стартовую вершину
    - Инициализируем массив ключей (∞) и родителей (-1)
2. Основной цикл:
    - Находим вершину с минимальным ключом
    - Добавляем её в MST
    - Обновляем ключи соседних вершин
    - Повторяем, пока все вершины не будут включены в MST
3. Завершение:
    - Формируем MST из массива родителей

- __инвариант__

    На каждом шаге алгоритма:

    1. Множество вершин в MST образует связное поддерево
    2. Для всех вершин вне MST хранится минимальный вес ребра, соединяющего их с MST
    3. Следующая добавляемая вершина гарантированно даёт минимальное расширение MST
- __оптимизация__: использование min-heap $O(logV)$ на операцию, кучи Фибоначчи $O(E + VlogV)$, ранняя остановка $(V-1)$

#### Псевдокод

```
// G — исходный граф
// w — весовая функция
function primFindMST():
 for v ∈ V(G)
       key[v] = ∞
       p[v] = null
    r = произвольная вершина графа G
    key[r] = 0

    Q.push(V(G))
 
    while not Q.isEmpty()
       v = Q.extractMin()
       for vu ∈ E(G)
           if u ∈ Q and key[u]>w(v,u)
               p[u] = v
               key[u] = w(v,u)
               Q.decreaseKey(u,key[u])
```

#### Пример кода

```cpp
typedef pair<int, int> pii;

vector<vector<pii>> adj;

void primMST(int V) {
    priority_queue<pii, vector<pii>, greater<pii>> pq;
    vector<int> key(V, INT_MAX);
    vector<int> parent(V, -1);
    vector<bool> inMST(V, false);

    pq.push({0, 0});
    key[0] = 0;

    while (!pq.empty()) {
        int u = pq.top().second;
        pq.pop();
        
        inMST[u] = true;

        for (auto &[weight, v] : adj[u]) {
            if (!inMST[v] && weight < key[v]) {
                key[v] = weight;
                parent[v] = u;
                pq.push({key[v], v});
            }
        }
    }
    cout << "Рёбра MST:\n";
    for (int i = 1; i < V; ++i)
        cout << parent[i] << " - " << i << " : " << key[i] << endl;
}
```

### Используемые структуры данных

- матрица смежности (для плотных графов)
- список смежности (для разреженных графов)
- массивы для хранения ключей и родителей

### Асимптотика

|          |Прима через массив|Прима через приорететную очередб|
|----------|--------------------|-----------------|
|По времени|$O(V^2)$|$O(ElogV)$|
|По памяти|$O(V + E)$|$O(V + E)$|

### Корректность алгоритма

### Применимость

- телекоммуникации, проектирование маршрутов, компьютерная графика

----

## Алгоритм Беллмана-Форда (кратчайший путь, но можно отрицательный вес ребра)

### Логика работы

1. Инициализация:
    - Установка расстояния до стартовой вершины = 0
    - Все остальные расстояния = ∞
2. Релаксация рёбер:
    - V-1 раз повторяем:

        Для каждого ребра (u, v) с весом w:

        Если d[u] + w < d[v], то обновляем d[v] = d[u] + w

3. Проверка на отрицательные циклы:
    - Если на V-ой итерации происходит обновление — есть отрицательный цикл

- *инвариант*
  - после i-й итерации внешнего цикла алгоритм находит все кратчайшие пути длиной ≤ i ребер
  - гарантирует нахождение кратчайших путей при отсутствии отрицательных циклов за V-1 итерацию
- *оптимизация*: ранняя остановка (если не происходит обновления `dist`), очередь, параллельная обработка

#### Псевдокод

```
bool fordBellman(s):
    for v ∈ V
  d[v] = 1
    d[s] = 0
    for i = 0 to |V|−1
        for (u,v) ∈ E
            if d[v] > d[u] + ω(u,v) // ω(u,v) — вес ребра uv
                d[v] = d[u] + ω(u,v)
    for (u,v) ∈ E
        if d[v] > d[u] + ω(u,v)
            return false
    return true
```

#### Пример кода

```cpp
struct Edge {
    int src, dest, weight;
};

void BellmanFord(vector<Edge>& edges, int V, int E, int src) {
    vector<int> dist(V, INT_MAX);
    dist[src] = 0;

    // Релаксация всех рёбер V-1 раз
    for (int i = 1; i <= V-1; i++) {
        for (const auto& edge : edges) {
            int u = edge.src;
            int v = edge.dest;
            int w = edge.weight;
            if (dist[u] != INT_MAX && dist[u] + w < dist[v]) {
                dist[v] = dist[u] + w;
            }
        }
    }

    // Проверка на отрицательные циклы
    for (const auto& edge : edges) {
        int u = edge.src;
        int v = edge.dest;
        int w = edge.weight;
        if (dist[u] != INT_MAX && dist[u] + w < dist[v]) {
            cout << "Граф содержит отрицательный цикл!" << endl;
            return;
        }
    }

    // Вывод результатов
    cout << "Вершина\tРасстояние от источника\n";
    for (int i = 0; i < V; ++i)
        cout << i << "\t\t" << dist[i] << endl;
}
```

### Используемые структуры данных

- список ребер
- список смежности
- матрица смежности

### Асимптотика

|              | Для списка смежности | Для списка ребер | Для матрицы смежности |
|--------------|----------------------|------------------|-----------------------|
| По времени   | $O(V \times E)$      | $O(V \times E)$  | $O(V^3)$              |
| По памяти    | $O(V)$           | $O(V)$           | $O(V)$              |

*в лучшем случае $O(E)$

### Корректность алгоритма

### Применимость

- маршрутизация в сетях
- обработка графиков зависимостей

-----

## Алгоритм DAG

### Чи шо

### Логика работы

1. Топологическая сортировка:
    - Упорядочиваем вершины так, чтобы все рёбра вели "вперёд"
2. Инициализация:
    - Расстояние до стартовой вершины = 0
    - До всех остальных = ∞
3. Релаксация рёбер:
    - Обрабатываем вершины в топологическом порядке
    - Для каждой вершины обновляем расстояния до её соседей

- __инвариант:__  
    При обработке вершины v, все возможные пути в v уже обработаны благодаря топологическому порядку.

- __оптимизация:__ использование битовых масок для малых DAG

```cpp
void topologicalSort(int v, vector<vector<pair<int, int>>>& adj, 
                    vector<bool>& visited, stack<int>& order) {...}

void DAG_ShortestPaths(vector<vector<pair<int, int>>>& adj, int V, int start) {
    stack<int> order;
    vector<bool> visited(V, false);
    
    // Топологическая сортировка
    for (int i = 0; i < V; ++i) {
        if (!visited[i]) {
            topologicalSort(i, adj, visited, order);
        }
    }
    
    // Инициализация расстояний
    vector<int> dist(V, INT_MAX);
    dist[start] = 0;
    
    // Обработка в топологическом порядке
    while (!order.empty()) {
        int u = order.top();
        order.pop();
        
        if (dist[u] != INT_MAX) {
            for (auto& [v, w] : adj[u]) {
                if (dist[v] > dist[u] + w) {
                    dist[v] = dist[u] + w;
                }
            }
        }
    }
}
```

### Используемые структуры данных

- список смежности
- стек (для топологической сортировки)
- массивы/векторы (хранение расстояний и порядка вершин)

### Асиптотика

|          |DAG|
|----------|----------------|
|По времени|$O(V + E)$|
|По памяти|$O(V)$|

### Корректность алгоритма

### Применимость

- системы планирования проектов
- задачи упорядоченного выполнения операций

-----

## Алгоритм Дейкстра с очередью/массивом

### Чи шо

### Логика работы

1. инициализация: расстояние в старте помечаем = 0, к остальным $\infty$
2. основной цикл: выбираем вершины с минимальным расстоянием, помечаем как посещенную, обновляем расстояния до соседей
3. завершение: когда все достижимые вершины обработаны

- __инвариант__  
    на каждом шаге алгоритма для всех посещенных вершин уже найдено кратчайшее расстояние до стартовой вершины, а для непосещенных хранится текущее наилучшее известное расстояние

- __оптимизация:__ min-heap, куча Фибоначчи

#### Псевдокод

```
func dijkstra(s):
    for v ∈ V     
        d[v] = ∞
        used[v] = false
    d[s] = 0
    for i ∈ V
        v = null
        for j ∈ V     // найдём вершину с минимальным расстоянием
            if !used[j] and (v == null or d[j] < d[v])
                v = j
        if d[v] == ∞
            break
        used[v] = true
        for e : исходящие из v рёбра     // произведём релаксацию по всем рёбрам исходящим из v
            if d[v] + e.len < d[e.to]
                d[e.to] = d[v] + e.len
```

#### Пример кода

##### Очередь

```cpp
typedef pair<int, int> pii; // (расстояние, вершина)

void dijkstra_queue(vector<vector<pii>>& graph, int start) {
    int V = graph.size();
    vector<int> dist(V, INT_MAX);
    vector<bool> visited(V, false);
    priority_queue<pii, vector<pii>, greater<pii>> pq;

    dist[start] = 0;
    pq.push({0, start});

    while (!pq.empty()) {
        int u = pq.top().second;
        pq.pop();
        
        if (visited[u]) continue;
        visited[u] = true;

        for (auto& [v, w] : graph[u]) {
            if (!visited[v] && dist[u] + w < dist[v]) {
                dist[v] = dist[u] + w;
                pq.push({dist[v], v});
            }
        }
    }
}
```

##### Массив

```cpp
void dijkstra_array(vector<vector<int>>& matrix, int start) {
    int V = matrix.size();
    vector<int> dist(V, INT_MAX);
    vector<bool> visited(V, false);

    dist[start] = 0;

    for (int count = 0; count < V-1; ++count) {
        // Находим вершину с минимальным dist
        int u = -1;
        for (int i = 0; i < V; ++i)
            if (!visited[i] && (u == -1 || dist[i] < dist[u]))
                u = i;

        visited[u] = true;

        // Обновляем соседей
        for (int v = 0; v < V; ++v)
            if (!visited[v] && matrix[u][v] && dist[u] + matrix[u][v] < dist[v])
                dist[v] = dist[u] + matrix[u][v];
    }
}
```

### Используемые структуры данных

- min-heap для хранения вершин с их текущими расстояниями
- массив/вектор для хранения кратчайших расстояний, посещенных вершин и предков
- реализация с очередью эффективна для разреженных графов, с массивом для плотных

### Асиптотика

|          |На куче|На массиве|
|----------|--------------------|-----------------|
|По времени|$O(E + VlogV)$|$O(V^2 + E)$|
|По памяти|$O(V)$|$O(V)$|

### Корректность алгоритма

### Применимость

- маршрутизация в сетях
- оптимизация транспортных маршрутов

-----

## Алгоритм Флойда-Уоршалла

### Чи шо

### Логика работы

1. инициализация: если есть ребра (i, j), то dist[i][j] = w, если нет ребра, то расстояние = $\infin$, dist[i][i] = 0 для всех i
2. далее используется дп
3. проверка на отрицательные циклы

- __инвариант__  
    после k итераций: матрица расстояний содержит кратчайшие пути, использующие в качестве промежуточных только вершины из множества {0 .. k-1}

- __оптимизация:__  
    если не нужно восстанавливать пути, можно использовать одну матрицу (без копирования), ранняя остановка при обнаружении отцательного цикла, использование битовых масок

#### Псевдокод

```
func floyd(w):
    d = ω // изначально d=ω
    for i ∈ V
        for u ∈ V
            for v ∈ V
                if d[u][i] + d[i][v] < d[u][v]
                    d[u][v] = d[u][i] + d[i][v]
                    next[u][v] = next[u][i]
```

#### Пример кода

```cpp
const int INF = numeric_limits<int>::max(); // Бесконечность

void floydWarshall(vector<vector<int>>& dist, int V) {
    for (int k = 0; k < V; k++) {         // Промежуточная вершина
        for (int i = 0; i < V; i++) {     // Начальная вершина
            for (int j = 0; j < V; j++) { // Конечная вершина
                if (dist[i][k] != INF && dist[k][j] != INF) { // Проверка на бесконечность
                    dist[i][j] = min(dist[i][j], dist[i][k] + dist[k][j]);
                }
            }
        }
    }
}
```

### Используемые структуры данных

- матрица смежности
- матрица предков (для восстановления путей)
- 3D—массив (в динамической версии)

### Асиптотика

|          |Флойд-Уоршалл|
|----------|--------------------|
|По времени|$O(V^3)$|
|По памяти|$O(V^2)$|

### Корректность алгоритма

### Применимость

- анализ транспортных сетей
- маршрутизация
- обработка графов с отрицательными весами (без циклов)

-----

## Поиск диаметра дерева

### Чи шо

### Логика работы

1. первый DFS/BFS: запускаем из произвольной вершины, находим самую удаленную вершину
2. второй DFS/BFS: запускаем уже из удаленной вершины, находим самую удаленную вершину для этой. расстояние между ними - это диаметр дерева

- __инвариант__
  - после первого поиска гарантированно найдется вершина Х, которая лежит на одном из концов диаметра
- __оптимизация__: для больших деревьев использовать BFS или разбиение на под-деревья, поиск центра дерева и исходить уже от него

#### Псевдокод

```
int diameterTree(list<list<int>> g):        
    v = u = w = 0
    d = bfs(g, v)
    for i = 0, i < n, i++
         if d[i] > d[u]
              u = i
    d = bfs(g, u)
    for i = 0, i < n, i++
          if d[i] > d[w]
               w = i
    return d[w]
```

#### Пример кода

```cpp
pair<int, int> bfs(int start, int V) {
    dist.assign(V, -1);
    queue<int> q;
    q.push(start);
    dist[start] = 0;
    
    int farthestNode = start;
    
    while (!q.empty()) {
        int node = q.front();
        q.pop();
        
        for (int neighbor : tree[node]) {
            if (dist[neighbor] == -1) { // Если ещё не посещали
                dist[neighbor] = dist[node] + 1;
                q.push(neighbor);
                farthestNode = neighbor;
            }
        }
    }
    
    return {farthestNode, dist[farthestNode]};
}

int findTreeDiameter(int V) {
    // Первый BFS от произвольной вершины (например, 0)
    int nodeX = bfs(0, V).first;
    
    // Второй BFS от самой удалённой вершины
    int diameter = bfs(nodeX, V).second;
    
    return diameter;
}
```

### Используемые структуры данных

- список смежности
- очередь для BFS или стек для DFS
- массив расстояний

### Асиптотика

|          |Поиск диаметра|
|----------|----------------|
|По времени|$O(V)$|
|По памяти|$O(V)$|

### Корректность алгоритма

### Применимость

- компьютерные сети
- оптимизация маршрутов

------

## Алгоритм Куна для поиска макс парсоч в двудольном графе

### Чи шо

### Логика работы

1. начинаем с пустого множества ребер
2. запускаем DFS из каждой вершины левой доли
3. ищем аугментирующий путь (путь, увеличивающий паросочетание)
4. переназначаем ребра, если нашли путь
5. повторяем, пока паросочетание увеличивается

- __инвариант__  
    на каждой итерации паросочетание либо остаётся прежним, либо увеличивается, а алгоритм гарантированно завершится через V итераций

- __оптимизация__  
    жадная инициализация (предварительно находим тривиальные пары, битовые маски

#### Псевдокод

```
bool dfs(v: int):
    if (used[v])
        return false
    used[v] = true
    for to in g[v]
        if (matching[to] == -1 or dfs(matching[to])):
            matching[to] = v
            return true 
    return false

function main():
    fill(matching, -1)
    for i = 1..n
         fill(used, false)
         dfs(i)
    for i = 1..n
         if (matching[i] != -1)
              print(i, " ", matching[i])
```

#### Пример кода

```cpp
// DFS для поиска аугментирующего пути
bool dfs(int u) {
    if (visited[u]) return false;
    visited[u] = true;
    
    for (int v : graph[u]) {
        if (match[v] == -1 || dfs(match[v])) {
            match[v] = u; // Назначаем новую пару
            return true;
        }
    }
    
    return false;
}

// Поиск максимального паросочетания
int kunAlgorithm(int leftSize, int rightSize) {
    match.assign(rightSize, -1); // Изначально все вершины правой доли свободны
    int maxMatching = 0;
    
    for (int u = 0; u < leftSize; u++) {
        visited.assign(leftSize, false);
        if (dfs(u)) maxMatching++;
    }
    
    return maxMatching;
}
```

### Используемые структуры данных

- список смежности
- массив совпадений
- массив посещений

### Асиптотика

|          |Кун для паросочетаний|
|----------|----------------|
|По времени|$O(V × E)$|
|По памяти|$O(V)$|

### Корректность алгоритма

### Применимость

- разделение задач
- компьютерное зрение

------

## Алгоритм Форда-Фалкерсона и Эдмондса-Карпа для поиска макс потока

### Чи шо

Алгоритм Форда-Фалкерсона

Алгоритм Эдмондса-Карпа — это оптимизированная версия алгоритма Форда-Фалкерсона, где поиск увеличивающих путей всегда осуществляется через BFS (поиск в ширину). Это гарантирует нахождение кратчайшего по количеству рёбер увеличивающего пути на каждом шаге.

### Логика работы

#### Форд-Фалкерсон

1. Находим увеличивающий путь (DFS из источника s в сток t).
2. Определяем бутылочное горлышко — минимальную пропускную способность на пути.
3. Обновляем остаточную сеть:
    - уменьшаем пропускную способность по прямым рёбрам,
    - увеличиваем по обратным (имитируем "обратный" поток).
4. Повторяем, пока есть увеличивающие пути.

- __инвариант__
  - поток остаётся допустимым: для всех вершин, кроме стока и истока выполняется закон сохранения потока, поток через любое ребро не превышает его капасити.
  - остаточная сеть корректно отражает возможности увеличения потока
  - увеличивающий путь всегда улучшает поток

##### Псевдокод

```
int dfs(int u, int flow):         
    if u = t
        return flow
    visited[u] = true                  
    for v in u.children
        auto uv = edge(u, v)
        if not visited[v] and uv.f < uv.c
            int bottleneck = dfs(v, min(Cmin, uv.c - uv.f))
            if bottleneck > 0
                uv.f += bottleneck
                uv.backEdge.f -= bottleneck
                return bottleneck
   return 0
```

##### Пример кода

```cpp
int dfs(int u, int t, int flow) {
    if (u == t) return flow;
    visited[u] = true;
    
    for (int v : adj[u]) {
        if (!visited[v] && capacity[u][v] > 0) { // Если есть ёмкость
            int bottleneck = dfs(v, t, min(flow, capacity[u][v]));
            if (bottleneck > 0) {
                capacity[u][v] -= bottleneck; // Обновляем остаточную сеть
                capacity[v][u] += bottleneck;
                return bottleneck;
            }
        }
    }
    return 0;
}

int maxFlow(int s, int t) {
    int flow = 0, newFlow;
    do {
        visited.assign(V, false);
        newFlow = dfs(s, t, INF);
        flow += newFlow;
    } while (newFlow > 0);
    
    return flow;
}
```

#### Эдмондс-Карп

1. __Инициализация__:
    - Поток на всех рёбрах = 0
    - Построить остаточную сеть
2. __Поиск увеличивающего пути__:
    - Всегда использует BFS для нахождения __кратчайшего пути__ в остаточной сети
3. __Обновление потока__:
    - Увеличить поток вдоль найденного пути на минимальную остаточную пропускную способность
4. __Повторять__, пока есть увеличивающие пути  

__инвариант__

На каждом шаге:

- Остаточная сеть корректно отражает доступные пути.
- Текущий поток не нарушает ограничения пропускных способностей.
- Поток в вершине (кроме источника и стока) сбалансирован

*Ключевая теорема*  
Теорема Эдмондса-Карпа:

- Алгоритм выполняет не более $O(V×E)$ увеличений потока
- Каждое увеличение требует $O(E)$ времени (BFS)
- Итоговая сложность: $O(V·E^2)$

##### Псевдокод

```
function EdmondsKarp(G, s, t):
    for (для) каждого ребра (u,v) ∈ E[G]
        f[u,v] ← 0
        f[v,u] ← 0
    while (существует кратчайший путь p из s в t в остаточной сети Gf)
        cf(p) ← min{ cf(u,v) : (u,v) ∈ p}
        for (u,v) ∈ p
            f[u,v] ← f[u,v] + cf(p)
            f[v,u] ← −f[u,v]

```

##### Пример кода

```cpp
int edmondsKarp(vector<vector<int>>& capacity, int source, int sink) {
    int n = capacity.size();
    vector<vector<int>> flow(n, vector<int>(n, 0));
    vector<int> parent(n);
    int max_flow = 0;

    while (true) {
        // BFS для поиска увеличивающего пути
        fill(parent.begin(), parent.end(), -1);
        parent[source] = -2;
        queue<pair<int, int>> q;
        q.push({source, INT_MAX});

        while (!q.empty()) {
            int u = q.front().first;
            int current_flow = q.front().second;
            q.pop();

            for (int v = 0; v < n; v++) {
                if (parent[v] == -1 && capacity[u][v] > flow[u][v]) {
                    parent[v] = u;
                    int new_flow = min(current_flow, capacity[u][v] - flow[u][v]);
                    if (v == sink) {
                        max_flow += new_flow;
                        // Обновляем поток вдоль пути
                        int node = v;
                        while (node != source) {
                            int prev = parent[node];
                            flow[prev][node] += new_flow;
                            flow[node][prev] -= new_flow;
                            node = prev;
                        }
                        break;
                    }
                    q.push({v, new_flow});
                }
            }
        }

        // Если не нашли путь - завершаем
        if (parent[sink] == -1)
            break;
    }

    return max_flow;
}
```

### Используемые структуры данных

- Форд-Фалкерсон
  - матрица смежности
  - список смежности
  - массив посещений
- Эдмондс-Карп
  - матрица смежности
  - список смежности
  - очередь для BFS
  - массив предков

### Асиптотика

|          |Форд-Фалкерсон|Эдмонндс-Карп|
|----------|----------------|------|
|По времени|$O(E × F)$|$O(V × E^2)$|
|По памяти|$O(V + E)$|$O(V^2)$|

*$F$ - значение максимального потока

### Корректность алгоритма

- при вещественных пропускных способностях алгоритм может не завершиться из-за бесконечной
- Эдмондс-Карп  
    __*Почему BFS улучшает алгоритм?*__  
    Гарантированная сходимость:
  - BFS всегда находит кратчайший путь
  - Длина кратчайшего пути монотонно возрастает (теорема Эдмондса-Карпа)  

    Ограничение числа итераций:
  - Максимум O(V*E) увеличивающих путей
  - Каждый BFS работает за O(E)

### Применимость

- оптимизация потоков
- логистика

-----

## Алгоритм Форда-Фалкерсона для поиска макс парсоч в двудольном графе

### Чи шо

### Логика работы

#### Шаги преобразования

1. __Создаем сеть потока__:
    - Направляем все ребра от левой доли к правой
    - Добавляем исток с ребрами ко всем вершинам левой доли
    - Добавляем сток со всеми ребрами от правой доли
2. __Пропускные способности__:
    - Все ребра имеют пропускную способность 1
3. __Запускаем Форда-Фалкерсона__:
    - Каждый единичный поток = одно ребро в паросочетании

- __инвариант__

    После каждой итерации:

  - Поток остаётся целочисленным (т. к. все пропускные способности = 1).

  - Размер паросочетания не убывает (каждый увеличивающий путь добавляет +1 к паросочетанию).

  - В конце алгоритма нет увеличивающих путей → паросочетание максимально.

#### Псевдокод

```
bool dfs(x):
    if vis[x]
        return false
    vis[x] = true
    for (x,y)∈E

        if py[y] == -1
            py[y] = x
            px[x] = y
            return true
        else
            if dfs(py[y])
                py[y] = x
                px[x] = y
                return true
    return false

func fordFulkerson():
    fill(px, -1)
    fill(py, -1)
    isPath = true
    while isPath
        isPath = false
        fill(vis, false)
        for x∈L

            if px[x] == -1
                if dfs(x)
                    isPath = true
```

#### Пример кода

```cpp
bool bfs(const vector<vector<int>>& residual, vector<int>& parent, int source, int sink) {
    fill(parent.begin(), parent.end(), -1);
    queue<int> q;
    q.push(source);
    parent[source] = -2;

    while (!q.empty()) {
        int u = q.front();
        q.pop();

        for (int v = 0; v < residual.size(); ++v) {
            if (parent[v] == -1 && residual[u][v] > 0) {
                parent[v] = u;
                if (v == sink) return true;
                q.push(v);
            }
        }
    }
    return false;
}

int fordFulkerson(vector<vector<int>>& graph, int source, int sink) {
    vector<vector<int>> residual = graph;
    vector<int> parent(graph.size());
    int max_matching = 0;

    while (bfs(residual, parent, source, sink)) {
        int path_flow = INT_MAX;
        for (int v = sink; v != source; v = parent[v]) {
            int u = parent[v];
            path_flow = min(path_flow, residual[u][v]);
        }

        for (int v = sink; v != source; v = parent[v]) {
            int u = parent[v];
            residual[u][v] -= path_flow;
            residual[v][u] += path_flow;
        }

        max_matching += path_flow;
    }

    return max_matching;
}

int maxBipartiteMatching(const vector<vector<int>>& bipartiteGraph, int leftSize) {
    int n = bipartiteGraph.size();
    int source = n, sink = n + 1;
    vector<vector<int>> flowNetwork(n + 2, vector<int>(n + 2, 0));

    // Соединяем исток с левой долей
    for (int u = 0; u < leftSize; ++u) {
        flowNetwork[source][u] = 1;
    }

    // Копируем исходный двудольный граф
    for (int u = 0; u < leftSize; ++u) {
        for (int v : bipartiteGraph[u]) {
            flowNetwork[u][v] = 1;
        }
    }

    // Соединяем правую долю со стоком
    for (int v = leftSize; v < n; ++v) {
        flowNetwork[v][sink] = 1;
    }

    return fordFulkerson(flowNetwork, source, sink);
}
```

### Используемые структуры данных

- список смежности/матрица смежности (хранение графа)
- очередь/стек (для BFS/DFS)
- массивы (родителей, посещенных вершин)

### Асиптотика

|          |Паросочетания|
|----------|-------------|
|По времени|$O(E × F)$|
|По памяти|$O(V + E)$|

*$F$ - размер паросочетания  

**в худшем случае для полных графов по времени: $O(E × V)$

### Корректность алгоритма

### Применимость

- системы рекомендаций
- распределение ресурсов

-----

## Поиск мостов и точек сочленения

### Чи шо

### Логика работы

Алгоритм основан на __обходе в глубину (DFS)__ с подсчётом:

- `tin[v]` — порядковый номер вершины при входе в DFS.
- `low[v]` — минимальный `tin`, достижимый из поддерева `v`.

#### __Поиск мостов__

Ребро `(u → v)` — __мост__, если `low[v] > tin[u]`.

#### __Поиск точек сочленения__

Вершина `u` — __точка сочленения__, если:

1. `u` — корень DFS-дерева __и__ имеет ≥ 2 детей.
2. `u` — не корень __и__ `low[v] ≥ tin[u]` для какого-то ребра `(u → v)`

- __инвариант:__
  - __После обработки вершины `v`__:
    - `low[v]` хранит минимальное `tin`, достижимое из `v` без использования родительского ребра.
    - Если `low[v] > tin[u]`, то ребро `(u → v)` — мост.
    - Если `low[v] ≥ tin[u]` и `u` не корень, то `u` — точка сочленения.
- __оптимизация__: ранний выход, итеративный DFS, удаление дубликатов

#### обход в глубину для поиск точек соочленения

```
function findCutPoints(G[n]: Graph): // функция принимает граф G с количеством вершин n и выполняет поиск точек сочленения во всем графе 
    visited = array[n, false]
                   
function dfs(v: int, p: int):
    time = time + 1
    low[v] = tin[v] = time 
    visited[v] = true
    count = 0             
    for u: (v, u) in G   
        if u == p
            continue
        if visited[u]
            low[v] = min(low[v], tin[u])
        else
            dfs(u, v) 
            count = count + 1
            low[v] = min(low[v], low[u])
            if p != -1 and low[u] >= tin[v]
                v — cutpoint 
    if p == -1 and count >= 2
        v — cutpoint 
                    
for i = 1 to n             
    if not visited[i]              
        dfs(i, -1)
```

#### Обход в глубину для поиска мостов

```
function dfs(v):
    time = time + 1
    tin[v] = time
    low[v] = time 
    for всех u смежных с v
        if (v, u) — обратное ребро
            low[v] = min(ret[v], tin[u])
        if вершина u — белая
            dfs(u)
            low[v] = min(low[v], low[u]) 
            if low[u] > tin[v] 
                ребро (v, u) — мост
```

### Используемые структуры данных

- список смежности/матрица смежности
- массивы
- стек (для DFS)

### Асиптотика

|          |Поиск мостов и ТС|
|----------|----------------|
|По времени|$O(V + E)$|
|По памяти|$O(V)$|

### Корректность алгоритма

### Применимость

- анализ надежности сетей
- построение двусвязных компонент (укладка графов)
- задачи на связность

-----

## Жадный алгоритм для поиска раскраски графа

### Чи шо

### Логика работы

1. Выбрать порядок вершин (например, по степени или произвольно).
2. Для каждой вершины:
    - Проверить цвета всех соседей.
    - Назначить минимальный доступный цвет (начиная с 1).

- __инвариант:__

    После раскраски каждой вершины никакие два соседа не имеют одинаковый цвет.

- __оптимизация:__ сортировка вершин, использование битовых масок

```cpp
vector<vector<int>> graph;  // Список смежности
vector<int> color;          // Цвета вершин (0 — не раскрашена)

void greedyColoring() {
    int V = graph.size();
    color.assign(V, 0);     // Изначально все вершины без цвета

    // Первая вершина — цвет 1
    color[0] = 1;

    for (int v = 1; v < V; ++v) {
        // Множество цветов соседей
        set<int> used_colors;

        // Проверяем всех соседей v
        for (int u : graph[v]) {
            if (color[u] != 0) {
                used_colors.insert(color[u]);
            }
        }

        // Находим минимальный доступный цвет
        int cr = 1;
        while (used_colors.count(cr)) {
            cr++;
        }
        color[v] = cr;
    }
}
```

### Используемые структуры данных

- список смежности/матрица смежности
- массив цветов
- множество/массив использованных цветов у соседей

### Асиптотика

|          |Карась_им|
|----------|----------------|
|По времени|$O(V^2 + E)$|
|По памяти|$O(V + E)$|

### Корректность алгоритма

### Применимость

- составление расписаний
- регистрация переменных в компиляторах
- задачи на картах
