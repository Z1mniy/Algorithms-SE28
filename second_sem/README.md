# Алгоритмы на графах

## Реализация структур хранения графа
- Список смежности
> Сложность по памяти: $O(V$ + сумма степеней всех вершин$)$ $= O(V + 2xE) = O(V + E)$

- Матрица смежности - это самый популярный и расточительный способ представления графа в памяти. Его уместно использовать, если граф плотный, т.е $E={\frac {V(V-1)}{2}}$.
> Сложность по памяти: $O(V^2)$

- Список ребер
> Сложность по памяти: $O(E)$

- Матрица инцидентности - не самый частый вариант хранения за счет затрат по памяти, в основном используют в прикладных задачах (телеком), а также любят в теории
> Сложность по памяти: $O(V × E)$
-----
## Обход в глубину DFS
### Логика работы
- __рекурсивная реализация:__ выбирается начальная вершина, она помечается как посещенная. далее рекурсивно: для текущей вершины просмтариваются все соседние, если соседняя не посещена, рекурсивно вызывается DFS для неё. после обработки всех вершин, происходит backtracking.

- __итеративная реализация:__ используется стек для хранения вершин, вершина извлекается из стека, обрабатывается, а ее непосещенные соседи добавляются в стек.

- __инвариант:__ все посещенные вершины достижимы из стартовой

- __оптимизация:__ битовая маска visited, ранний выход

#### Псевдокод
```
function doDfs(G[n]: Graph): // функция принимает граф G с количеством вершин n и выполняет обход в глубину во всем графе 
   visited = array[n, false]  // создаём массив посещённых вершины длины n, заполненный false изначально
          
   function dfs(u: int):   
      visited[u] = true
      for v: (u, v) in G        
         if not visited[v]               
            dfs(v)

   for i = 1 to n             
      if not visited[i]                    
         dfs(i)
```
#### Пример рекурсивной реализации
```cpp
void dfsRecursive(int v, int from, const vector<vector<int>>& graph, vector<bool>& visited) {
    if (visited[v]) return;
    visited[v] = true;
    for (int to : graph[v]) {
        if (to == from) continue;
        dfsRecursive(to, v, graph, visited);
    }
}
```
#### Пример итеративной реализации
```cpp
void dfsIterative(const vector<vector<int>>& graph, int start) {
    vector<bool> visited(V, false);
    stack<int> stack;
    stack.push(start);
    
    while (!stack.empty()) {
        int v = stack.top();
        stack.pop();
        
        if (!visited[v]) {
            visited[v] = true;
            //можно добавить кастомную обработку вершины ...
            for (auto it = graph[v].rbegin(); it != graph[v].rend(); ++it) {
                if (!visited[v]) {
                    stack.push(*it);
                }
            }
        }
    }
}
```
### Используемые структуры данных
- рекурсивная реализация использует стек вызовов
- итеративная реализация - явный стек
- массив/множество visited
### Асимптотика
|          |Список смежности|Матрица смежности|Список ребер|
|----------|--------------------|-----------------|------------|
|По времени|$O(V + E)$|$O(V^2)$|$O(V + E)$|
|По памяти|$O(V)$|$O(V^2)$|$O(V)$|
### Ограничения и плюсы

### Применимость
- Поиск компонент связности.
- Топологическая сортировка (DAG).
- Поиск циклов, мостов, точек сочленения.
- Генерация лабиринтов, решение головоломок.


------

## Обход в ширину BFS 
### Логика работы
- выбирается начальная вершина, она помечается как посещенная и добавляется в очередь. извлекается вершина из очереди, обрабатываются все ее соседи, если соседняя вершина не посещена, она помечается как посещенная и добавляется в очередь. процесс продолжается,ю пока очередь не станет пустой.
- __инвариант__: все вершины в очереди находятся на расстоянии `d` или `d+1` от стартовой
- __оптимизация__:
    
    - вусторонний BFS (Bidirectional BFS) – если известна целевая вершина, запускаем BFS одновременно из старта и цели. 
    
    - Использование deque (если граф 0-1, как в алгоритме 0-1 BFS).
    
    - Сжатие координат (если вершины – точки на сетке).
    
    - Ранний выход (если нашли нужную вершину)
#### Псевдокод
- $source$ — исходная вершина
- $destination$ — конечная вершина
- $G$ — граф, состоящий из списка вершин V и списка смежности E. Вершины нумеруются целыми числами.
- $Q$ — очередь.
- В поле `d[u]` хранится расстояние от source до u.
```
int BFS(G: (V, E), source: int, destination: int):
    d = int[|V|]
    fill(d, ∞)
    d[source] = 0
    Q = ∅

    Q.push(source)
    while Q ≠∅
 
        u = Q.pop()
        for v: (u, v) in E
            if d[v] == ∞

                d[v] = d[u] + 1
                Q.push(v)
    return d[destination]
```
#### Пример кода
```cpp
void BFS(const vector<vector<int>>& graph, int start) {
	queue<int> q;
	vector<bool> visited(graph.size(), false);
	q.push(start);
	visited[start] = true;
	
	while (!q.empty()) {
		int v = q.front();
		q.pop();
		//...
		for (int neighbor : graph[v]) {
			if (!visited[neighbor]) {
				visited[neighbor] = true;
				q.push(neighbor);
			}
		}
	}
}
```

### Используемые структуры данных
- массив посещенных вершин
- очередь. всегда ее используем

### Асимптотика
|          |Список смежности|Матрица смежности|Список ребер|
|----------|--------------------|-----------------|------------|
|По времени|$O(V + E)$|$O(V^2)$|$O(V + E)$|
|По памяти|$O(V)$|$O(V^2)$|$O(V)$|

### Ограничения и плюсы

### Применимость
- поиск кратчайшего пути в невзвешенном графе
- проверка на двудольность
- поиск компонент связности
- поиск ближайших соседей



-----

## Топологическая сортировка 
### Чи шо вообще
Это упорядочивание вершин таким образом, что для любого ребра (u, v) вершина u всегда стоит перед вершиной v.

Задача топологической сортировки графа звучит так: дан ориентированный граф, и требуется найти такой порядок вершин, в котором все рёбра графа вели из более ранней вершины в более позднюю.

### Логика работы
- __DFS__ при завершении обхода вершины, добавляем ее в стек, затем его разворачиваем. (либо сразу в конец без стека)
- __алгоритм Кана__ считаем входные степени вершин, добавляем вершины с входной степенью 0 в очередь. удаляем вершины из очереди, уменьшаемм входные степени их соседей. если вершина с входной степенью 0 появилась - добавляем ее в очередь. повторяем, пока не обработаем все вершины.
- __инвариант__: вершина добавляется в порядок только после всех своих потомков (DFS); в очереди всегда находятся вершины с `in_degree = 0`, гарантируя корректный порядок (Kana).


#### Псевдокод
```
// G — исходный граф
function topologicalSort(): проверить граф G на ацикличность
    fill(visited,false)
    for v∈V(G)
        if not visited[v]
             dfs(v)
    ans.reverse()

function dfs(u):
    visited[u]=true
    for uv ∈ E(G)
        if not visited[v]
            dfs(v)
    ans.pushBack(u)
```

#### Топологическая сортировка 
```cpp
void tSort(std::vector<std::vector<int>>& graph, int v, std::vector<int>& visited, std::vector<int>& order) {
    visited[v] = 1;
    for (int to : graph[v]) {
        if (visited[to] == 0) {
            tSort(graph, to, visited, order);
        }
    }
    order.push_back(v);
}
```

#### Алгоритм Кана
```cpp
vector<int> tSortKana(int v, vector<vector<int>>& edges) {
	vector<int> in_degree(V, 0);
	vector<vector<int>> adj(V);
	vector<int> result;
	
	for (const auto& edge : edges) {
		int u = edge[0], v = edge[1];
		adg[u].push_back(v);
		in_degree[v]++;
	}
	
	queue<int> q;
	for (int i = 0; i < V; ++i) {
		if (in_degree[i] == 0) {
			q.push(i);
		}
	}
	
	while (!q.empty()) {
		int node = q.front();
		q.pop();
		result.push_back(node);
		
		for (int neighbor : adj[node]) {
			in_degree[neighbor]--;
			if (in_degree[neighbor] == 0) {
				q.push(neighbor);
			}
		}
	}
	
	return result;
}
```

### Используемые структуры данных
- массив посещенных
- стек (DFS)
- очередь (алгоритм Кана)

### Асимптотика
|          |Список смежности|Матрица смежности|
|----------|--------------------|-----------------|
|По времени|$O(V + E)$|$O(V^2)$|
|По памяти|$O(V)$|$O(V)$|

### Ограничения и плюсы

### Применимость
- планирование задач с зависимостями
- разрешение зависимостей в системах управления пакетами
- обход графа зависимостей в базах данных и анализе сетей





-----

## Конденсация графа + поиск комп слабой свзяности

### Чи шо вообще
__Конденсацией__ орграфа $G$ называют такой орграф $G'$, вершинами которого служат компоненты сильной связности $G$, а дуга в $G'$ присутствует только если существует хотя бы одно ребро между вершинами, входящими в соответствующие компоненты связности. Конденсация графа не содержит кратных ребер.

__Слабая связность__ - вершины связаны в неориентированой версии графа.

__Сильная связность__ - пары вершин - путь.

### Логика работы
- __поиск wcc через dfs/bfs__
    
    идем по всем вершинам. если вершина не посещена, запускаем один из обходов. обходим все ребра. все посещенные вершины относятся к одной компоненте. повторяем пока не покроем все вершины.
    
- __конденсация графа__ (scc + построение dag)
    
    для поиска scc используем алгоритм Косараджу или Тарьяна
    
    >Косараджу: основан на dfs и транспониировании графа. Требует два полных обхода графа (один для сортировки, второй для обхода транспонированного). Логика работы: запускаем обход и кладём вершины в стек по завершении обхода, меняем направления всех ребер. запускаем второй dfs на транспонированном графе, достаём из стека и запускаем обход, каждое новое дерево dfs - scc
    
    >Тарьяна: основан на 1 dfs с поддержкой времени входа и низкой связи. назначаем каждой вершине entry time (бесконечное время входа), если встречаем обратное ребро обновляем low-link. если entry[v]==low[v], то вершина - корень scc, достаем все вершины из стека, пока не достигнем v.
    
    __scc__ - множество вершин, из которых можно добраться друг до друга. каждая scc становится одной вершиной. если из одной scc есть путь в другую, добавляем ребро

#### Псевдокод
```
function dfs1(v):                                          
	color[v] = 1
	for (v, u) in E
		if not visited[u]
			dfs1(G[v][u])
	Добавляем вершину v в конец списка ord

function dfs2(v):                                          
	component[v] = col
	for (v, u) in E
		if (вершина u еще не находится ни в какой компоненте)                       
			dfs2(H[v][u])

function main():
	считываем исходные данные, формируем массивы G и H
	for u in V                           
		if not visited[u]
			dfs1(u)
	col = 1
	for (по всем вершинам u списка ord[] в обратном порядке)                                                        
		if (вершина u не находится ни в какой компоненте)
			dfs2(u)
			col++
```
#### Поиск компонент слабой связности
```cpp
void dfs(int v, vector<vector<int>>& adj, vector<bool>& visited) {...}


int WCC(int V, vector<pair<int, int>>& edges) {
	vector<vector<int>> adj(V);
	vector<bool> visited(V, false);
	
	for (auto& edge : edges) {
		adj[edge.first].push_back(edge.second);
		adj[edge.second].push_back(edge.first);
	}
	
	int components = 0;
	for (int i = 0; i < V; ++i) {
		if (!visited[i]) {
				dfs(i, adj, visited);
				components++:
		}
	}
	return components;
}
```
#### Поиск компонент сильной связности Косораджу
```cpp
void dfs1(int v, vector<vector<int>>& agj, vector<bool>& visited, stack<int>& order) {...}
void dfs2(int v, vector<vector<int>>& reverse_adj, vector<bool>& visited, vector<int>& component) {...}


vector<vector<int>> findSCC(int V, vector<pair<int, int>>& edges) {
	vector<vector<int>> adj(V), reverse_adj(V);
	vector<bool> visited(V, false);
	stack<int> order;
	
	for (auto& edge : edges) {
		adj[edge.first].push_back(edge.second);
		reverse_adj[edge.second].push_back(edge.first);
	}
	
	for (int i = 0; i < V; ++i) {
		if (!visited[i]) dfs1(i, adj, visited, order);
	}
	
	fill(visited.begin(), visited.end(), false);
	vector<vector<int>> sccs;
	while (!order.empty()) {
		int v = order.top();
		order.pop();
		if (!visited[v]) {
			vector<int> component;
			dfs2(v, reverse_adj, visited, component);
			sccs.push_back(component);
		}
	}
	return sccs;
}
```
### Используемые структуры данных
- орграф и неориентированный граф
- список смежности
- матрица смежности
- очередь или стек для обхода
- __DSU(Union-Find)__ - для эффективного объединения компонент.
    
    это структура данныз, которая поддерживает динамическое объединение множеств и поиск представителя множества.
    
    без оптимизации работает за $O(n)$, с оптимизацией за $O( \alpha n)$ используется сжатие пути + ранг(глубина)
    
    подходит только для динамических непересекающихся множеств. не дает прямой информации о количестве элементов в каждом множестве. очень быстрая работа почти за $O(1)$


### Асимптотика
|          |Поиск компонент слабой связности с использование DFS/BFS|Поиск компонент слабой связности Union-find|Конденсация графа с использованием Косарайю/Тарьяна|
|----------|--------------------|-----------------|------------|
|По времени|$O(V + E)$|$O(\alpha(V))$|$O(V + E)$|
### Ограничения и плюсы
### Применимость
- анализ сетей (группировка узлов)
- разбиение зависимостей
- моделирование






----

## Поиск и восстановление всех видов циклов 

### Логика работы
- используем один из обходов. при обходе сохраняем текущий путь, если обнаруживается вершина, которая уже находится в текущем пути, значит мы нашли цикл. цикл восстановляется из текущего пути.

```cpp
void findCyclesDFS(int v, int parent, const vector<vector<int>>& graph, vector<bool>& visited, vector<int>& path, vector<vector<int>>& cycles) {
    visited[v] = true;
    path.push_back(v);

    for (int neighbor : graph[v]) {
        if (!visited[neighbor]) {
            findCyclesDFS(neighbor, v, graph, visited, path, cycles);
        } else if (neighbor != parent) {
            vector<int> cycle;
            int start = neighbor;
            int i = path.size() - 1;
            while (path[i] != start) {
                cycle.push_back(path[i]);
                i--;
            }
            cycle.push_back(start);
            cycles.push_back(cycle);
        }
    }

    path.pop_back();
}
```
### Используемые структуры данных
- стек, список смежности, матрица смежности, очередь
### Асимптотика
|          |Нахождение цикла|Востановление циклов ($C$ - кол-во циклов для востановления )|
|----------|--------------------|-----------------|
|По времени|$O(V + E)$|$O(C*(V + E))$|

### Ограничения и плюсы
### Применимость
- анализ в многопоточных программах



----
## Поиск Гамильтонова цикла при выполнении достаточных условий
### Чи шо вообще
Замкнутый простой путь, проходящий через каждую вершину графа ровно один раз.
### Логика работы
- выбирается начальная вершина, рекурсивно: для текущей вершины проверяются все непосещенные соседи, если она не посещена, она добавляется в текущий путь. если путь содержит все вершины и есть ребро обратно в начальную вершину, найден гамильтов цикл

#### Псевдокод
```
function findHamiltonianCycle(⟨V,E⟩):
	for v∈V:                                          // Добавляем все вершины графа в очередь
	queue.pushBack(v)
	for k = 0..n * (n - 1)
	if (queue.at(0), queue.at(1)) ∉ E // Проверяем существования ребра между первой и второй вершинами очереди
		i = 2                                             
		while (queue.at(0), queue.at(i)) ∉ E or (queue.at(1), queue.at(i + 1)) ∉E
			i++                                         // Ищем индекс удовлетворяющую условию вершины
		queue.swapSubQueue(1, i)                        // Разворачиваем часть перестановки от 1-й до найденной позиции включительно
	queue.pushBack(queue.top())
	queue.pop()
```
#### Пример кода
```cpp
bool isSafe(int v, const vector<vector<int>>& graph, const vector<int>& path, int pos) {
    if (graph[path[pos - 1]][v] == 0) {
        return false;
    }
    for (int i = 0; i < pos; ++i) {
        if (path[i] == v) {
            return false;
        }
    }

    return true;
}

bool hamiltonianCycleUtil(const vector<vector<int>>& graph, vector<int>& path, int pos) {
    int n = graph.size();
    if (pos == n) {
        if (graph[path[pos - 1]][path[0]] == 1) {
            return true;
        } else {
            return false;
        }
    }

    for (int v = 1; v < n; ++v) {
        if (isSafe(v, graph, path, pos)) {
            path[pos] = v;
            if (hamiltonianCycleUtil(graph, path, pos + 1)) {
                return true;
            }
            path[pos] = -1;
        }
    }

    return false;
}
```

### Используемые структуры данных
- список смежности, матрица смежности

### Асимптотика
|          |Стандартный случай|Худший случай|
|----------|--------------------|-----------|
|По времени|$O(n^2)$|$O(n!)$|
|По памяти|$O(V)$|$O(V)$|

### Ограничения и плюсы

### Применимость
- поиск оптимальных маршрутов
- анализ сетей




----
## Поиск Эйлерова цикла 

### Чи шо вообще
Замкнутый путь, который проходит по каждому ребру, причем ровно один раз.

### Логика работы
- используем DFS, ребра удаляются после их посещения, вершины добавляются в цикл в порядке их завершения

```cpp
void eulerianCycleUtil(int v, vector<vector<int>>& graph, vector<int>& cycle) {
    while (!graph[v].empty()) {
        int u = graph[v].back();
        graph[v].pop_back();
        eulerianCycleUtil(u, graph, cycle);
    }
    cycle.push_back(v);
}

vector<int> findEulerianCycle(vector<vector<int>>& graph, int numVertices) {
    vector<int> cycle;
    for (int i = 0; i < numVertices; ++i) {
        if (graph[i].size() % 2 != 0) {
            cout << "Эйлеров цикл не существует" << endl;
            return {};
        }
    }
    eulerianCycleUtil(0, graph, cycle);
    for (int i = 0; i < numVertices; ++i) {
        if (!graph[i].empty()) {
            cout << "Эйлеров цикл не существует" << endl;
            return {};
        }
    }
    reverse(cycle.begin(), cycle.end());
    return cycle;
}
```

### Используемые структуры данных
- список смежности, матрица смежности

### Асимптотика
|          |Поиск Эйлерового цикла|
|----------|--------------------|
|По времени|$O(V + E)$|
|По памяти|$O(V + E)$|

### Ограничения и плюсы

### Применимость
- поиск оптимальных маршрутов
- анализ сетей





------

## Нахождение компонент связности в неориентированном графе 

### Чи шо вообще
Набор вершин графа, между любой парой которых существует путь
### Логика работы
- создаем массив доля хранения посещенных вершин, при обходе для каждой непосещенной вершины запускаем обход, ве вершины, достижимые из текущей будут включены в одному компоненту связности. повторяем процесс, пока все вершины не будут посещены.
```cpp
void dfs(int v, const vector<vector<int>>& graph, vector<bool>& visited, vector<int>& component) {
    visited[v] = true;
    component.push_back(v);

    for (int neighbor : graph[v]) {
        if (!visited[neighbor]) {
            dfs(neighbor, graph, visited, component);
        }
    }
}

vector<vector<int>> findConnectedComponents(const vector<vector<int>>& graph, int numVertices) {
    vector<bool> visited(numVertices, false);
    vector<vector<int>> components;

    for (int i = 0; i < numVertices; ++i) {
        if (!visited[i]) {
            vector<int> component;
            dfs(i, graph, visited, component);
            components.push_back(component);
        }
    }

    return components;
}
```
### Используемые структуры данных
- список смежности, матрица смежности
### Асимптотика
|          |Поиск комопонент связности|
|----------|--------------------|
|По времени|$O(V + E)$|
|По памяти|$O(V)$|
### Ограничения и плюсы
### Применимость
- анализ графов (электрические цепи, транспортные сети)






-----
## Алгоритмы Краскала 
### Логика работы
- сортируем ребра по возрастанию. Каждая вершина графа будет представлять собой отдельное множество. далее обход ребер: для каждого ребра проверяется, принадлежат ли его вершины разным множества, если да, то ребро добавляется в остовое дерева, а множества объединяются, если нет, то ребро пропускается (иначе мы получим цикл). процесс продолжает пока не обработаны все ребра или пока не будет найдено V - 1 ребро.
- __инвариант__: на каждом шаге алгоритма множество выбранных ребер образует лес(набор деревьев) и каждое новое ребро добавляется так, чтобы не образовывать циклов
- __оптимизация__: сортировка ребер, ранняя остановка (V - 1 ребро), параллельная обработка (несколько потоков обработки)

```cpp
struct Edge {
    int src, dest, weight;
};

class DSU {
    vector<int> parent, rank;

public:
    DSU(int n) {
        parent.resize(n);
        rank.resize(n, 0);
        for (int i = 0; i < n; ++i) {
            parent[i] = i;
        }
    }
    
    int find(int u) {
        if (parent[u] != u) {
            parent[u] = find(parent[u]);
        }
        return parent[u];
    }

    void unite(int u, int v) {
        int rootU = find(u);
        int rootV = find(v);

        if (rootU != rootV) {
            if (rank[rootU] > rank[rootV]) {
                parent[rootV] = rootU;
            } else if (rank[rootU] < rank[rootV]) {
                parent[rootU] = rootV;
            } else {
                parent[rootV] = rootU;
                rank[rootU]++;
            }
        }
    }
};

bool compareEdges(const Edge& a, const Edge& b) {
    return a.weight < b.weight;
}

vector<Edge> kruskalMST(vector<Edge>& edges, int numVertices) {
    sort(edges.begin(), edges.end(), compareEdges);

    DSU dsu(numVertices);
    vector<Edge> mst;

    for (const Edge& edge : edges) {
        int u = edge.src;
        int v = edge.dest;
        if (dsu.find(u) != dsu.find(v)) {
            mst.push_back(edge);
            dsu.unite(u, v);
        }
    }

    return mst;
}
```
### Используемые структуры данных
- список ребер
- система непересекающихся множеств
### Асимптотика
|          |Краскал|
|----------|--------------------|
|По времени|$O(ElogE)$|
|По памяти|$O(V + E)$|
### Ограничения и плюсы
### Применимость
- поиск MST
- решение задач с минимизацией суммарного веса ребер





----

## Алгоритм Прима 
### Логика работы
1. Инициализация:
    - Выбираем произвольную стартовую вершину
    - Инициализируем массив ключей (∞) и родителей (-1)
2. Основной цикл:
    - Находим вершину с минимальным ключом
    - Добавляем её в MST
    - Обновляем ключи соседних вершин
    - Повторяем, пока все вершины не будут включены в MST
3. Завершение:
    - Формируем MST из массива родителей
- __инвариант__
    
    На каждом шаге алгоритма:
    
    1. Множество вершин в MST образует связное поддерево
    2. Для всех вершин вне MST хранится минимальный вес ребра, соединяющего их с MST
    3. Следующая добавляемая вершина гарантированно даёт минимальное расширение MST
- __оптимизация__: использование min-heap $O(logV)$ на операцию, кучи Фибоначчи $O(E + VlogV)$, ранняя остановка $(V-1)$

#### Псевдокод
```
// G — исходный граф
// w — весовая функция
function primFindMST():
	for v ∈ V(G)
       key[v] = ∞
       p[v] = null
   	r = произвольная вершина графа G
   	key[r] = 0

   	Q.push(V(G))
 
   	while not Q.isEmpty()
       v = Q.extractMin()
       for vu ∈ E(G)
           if u ∈ Q and key[u]>w(v,u)
               p[u] = v
               key[u] = w(v,u)
               Q.decreaseKey(u,key[u])
```

#### Пример кода
```cpp
typedef pair<int, int> pii;

vector<vector<pii>> adj;

void primMST(int V) {
    priority_queue<pii, vector<pii>, greater<pii>> pq;
    vector<int> key(V, INT_MAX);
    vector<int> parent(V, -1);
    vector<bool> inMST(V, false);

    pq.push({0, 0});
    key[0] = 0;

    while (!pq.empty()) {
        int u = pq.top().second;
        pq.pop();
        
        inMST[u] = true;

        for (auto &[weight, v] : adj[u]) {
            if (!inMST[v] && weight < key[v]) {
                key[v] = weight;
                parent[v] = u;
                pq.push({key[v], v});
            }
        }
    }
    cout << "Рёбра MST:\n";
    for (int i = 1; i < V; ++i)
        cout << parent[i] << " - " << i << " : " << key[i] << endl;
}
```
### Используемые структуры данных
- матрица смежности (для плотных графов)
- список смежности (для разреженных графов)
- массивы для хранения ключей и родителей
### Асимптотика
|          |Прима через массив|Прима через приорететную очередб|
|----------|--------------------|-----------------|
|По времени|$O(V^2)$|$O(ElogV)$|
|По памяти|$O(V + E)$|$O(V + E)$|
### Ограничения и плюсы
### Применимость
- телекоммуникации, проектирование маршрутов, компьютерная графика






----
## Алгоритм Беллмана-Форда (кратчайший путь, но можно отрицательный вес ребра)
### Логика работы
1. Инициализация:
    - Установка расстояния до стартовой вершины = 0
    - Все остальные расстояния = ∞
2. Релаксация рёбер:
    - V-1 раз повторяем:
        
        Для каждого ребра (u, v) с весом w:
        
        Если d[u] + w < d[v], то обновляем d[v] = d[u] + w
        
3. Проверка на отрицательные циклы:
    - Если на V-ой итерации происходит обновление — есть отрицательный цикл
- *инвариант*
    - после i-й итерации внешнего цикла алгоритм находит все кратчайшие пути длиной ≤ i ребер
    - гарантирует нахождение кратчайших путей при отсутствии отрицательных циклов за V-1 итерацию
- *оптимизация*: ранняя остановка (если не происходит обновления `dist`), очередь, параллельная обработка
#### Псевдокод
```
bool fordBellman(s):
    for v ∈ V
		d[v] = 1
    d[s] = 0
    for i = 0 to |V|−1
        for (u,v) ∈ E
            if d[v] > d[u] + ω(u,v) // ω(u,v) — вес ребра uv
                d[v] = d[u] + ω(u,v)
    for (u,v) ∈ E
        if d[v] > d[u] + ω(u,v)
            return false
    return true
```
#### Пример кода
```cpp
struct Edge {
    int src, dest, weight;
};

void BellmanFord(vector<Edge>& edges, int V, int E, int src) {
    vector<int> dist(V, INT_MAX);
    dist[src] = 0;

    // Релаксация всех рёбер V-1 раз
    for (int i = 1; i <= V-1; i++) {
        for (const auto& edge : edges) {
            int u = edge.src;
            int v = edge.dest;
            int w = edge.weight;
            if (dist[u] != INT_MAX && dist[u] + w < dist[v]) {
                dist[v] = dist[u] + w;
            }
        }
    }

    // Проверка на отрицательные циклы
    for (const auto& edge : edges) {
        int u = edge.src;
        int v = edge.dest;
        int w = edge.weight;
        if (dist[u] != INT_MAX && dist[u] + w < dist[v]) {
            cout << "Граф содержит отрицательный цикл!" << endl;
            return;
        }
    }

    // Вывод результатов
    cout << "Вершина\tРасстояние от источника\n";
    for (int i = 0; i < V; ++i)
        cout << i << "\t\t" << dist[i] << endl;
}
```
### Используемые структуры данных
- список ребер
- список смежности
- матрица смежности

### Асимптотика
|              | Для списка смежности | Для списка ребер | Для матрицы смежности |
|--------------|----------------------|------------------|-----------------------|
| По времени   | $O(V \times E)$      | $O(V \times E)$  | $O(V^3)$              |
| По памяти    | $O(V + E)$           | $O(E)$           | $O(V^2)$              |


*в лучшем случае $O(E)$

### Ограничения и плюсы
### Применимость
- маршрутизация в сетях
- обработка графиков зависимостей


-----

## Алгоритм DAG 
### Чи шо
### Логика работы
1. Топологическая сортировка:
    - Упорядочиваем вершины так, чтобы все рёбра вели "вперёд"
2. Инициализация:
    - Расстояние до стартовой вершины = 0
    - До всех остальных = ∞
3. Релаксация рёбер:
    - Обрабатываем вершины в топологическом порядке
    - Для каждой вершины обновляем расстояния до её соседей
- __инвариант:__  
    При обработке вершины v, все возможные пути в v уже обработаны благодаря топологическому порядку.
    
- __оптимизация:__ использование битовых масок для малых DAG

```cpp
void topologicalSort(int v, vector<vector<pair<int, int>>>& adj, 
                    vector<bool>& visited, stack<int>& order) {...}

void DAG_ShortestPaths(vector<vector<pair<int, int>>>& adj, int V, int start) {
    stack<int> order;
    vector<bool> visited(V, false);
    
    // Топологическая сортировка
    for (int i = 0; i < V; ++i) {
        if (!visited[i]) {
            topologicalSort(i, adj, visited, order);
        }
    }
    
    // Инициализация расстояний
    vector<int> dist(V, INT_MAX);
    dist[start] = 0;
    
    // Обработка в топологическом порядке
    while (!order.empty()) {
        int u = order.top();
        order.pop();
        
        if (dist[u] != INT_MAX) {
            for (auto& [v, w] : adj[u]) {
                if (dist[v] > dist[u] + w) {
                    dist[v] = dist[u] + w;
                }
            }
        }
    }
}
```
### Используемые структуры данных
- список смежности
- стек (для топологической сортировки)
- массивы/векторы (хранение расстояний и порядка вершин)
### Асиптотика
|          |DAG|
|----------|----------------|
|По времени|$O(V + E)$|
|По памяти|$O(V)$|

### Ограничения и плюсы
### Применимость
- системы планирования проектов
- задачи упорядоченного выполнения операций




-----
## Алгоритм Дейкстра с очередью/массивом 
### Чи шо
### Логика работы
1. инициализация: расстояние в старте помечаем = 0, к остальным $\infty$
2. основной цикл: выбираем вершины с минимальным расстоянием, помечаем как посещенную, обновляем расстояния до соседей
3. завершение: когда все достижимые вершины обработаны
- __инвариант__  
    на каждом шаге алгоритма для всех посещенных вершин уже найдено кратчайшее расстояние до стартовой вершины, а для непосещенных хранится текущее наилучшее известное расстояние
    
- __оптимизация:__ min-heap, куча Фибоначчи

#### Псевдокод
```
func dijkstra(s):
    for v ∈ V     
        d[v] = ∞
        used[v] = false
    d[s] = 0
    for i ∈ V
        v = null
        for j ∈ V     // найдём вершину с минимальным расстоянием
            if !used[j] and (v == null or d[j] < d[v])
                v = j
        if d[v] == ∞
            break
        used[v] = true
        for e : исходящие из v рёбра     // произведём релаксацию по всем рёбрам исходящим из v
            if d[v] + e.len < d[e.to]
                d[e.to] = d[v] + e.len
```
#### Пример кода
##### Очередь
```cpp
typedef pair<int, int> pii; // (расстояние, вершина)

void dijkstra_queue(vector<vector<pii>>& graph, int start) {
    int V = graph.size();
    vector<int> dist(V, INT_MAX);
    vector<bool> visited(V, false);
    priority_queue<pii, vector<pii>, greater<pii>> pq;

    dist[start] = 0;
    pq.push({0, start});

    while (!pq.empty()) {
        int u = pq.top().second;
        pq.pop();
        
        if (visited[u]) continue;
        visited[u] = true;

        for (auto& [v, w] : graph[u]) {
            if (!visited[v] && dist[u] + w < dist[v]) {
                dist[v] = dist[u] + w;
                pq.push({dist[v], v});
            }
        }
    }
}
```
##### Массив
```cpp
void dijkstra_array(vector<vector<int>>& matrix, int start) {
    int V = matrix.size();
    vector<int> dist(V, INT_MAX);
    vector<bool> visited(V, false);

    dist[start] = 0;

    for (int count = 0; count < V-1; ++count) {
        // Находим вершину с минимальным dist
        int u = -1;
        for (int i = 0; i < V; ++i)
            if (!visited[i] && (u == -1 || dist[i] < dist[u]))
                u = i;

        visited[u] = true;

        // Обновляем соседей
        for (int v = 0; v < V; ++v)
            if (!visited[v] && matrix[u][v] && dist[u] + matrix[u][v] < dist[v])
                dist[v] = dist[u] + matrix[u][v];
    }
}
```
### Используемые структуры данных
- min-heap для хранения вершин с их текущими расстояниями
- массив/вектор для хранения кратчайших расстояний, посещенных вершин и предков
- реализация с очередью эффективна для разреженных графов, с массивом для плотных
### Асиптотика
|          |На куче|На массиве|
|----------|--------------------|-----------------|
|По времени|$O(E + VlogV)$|$O(V^2 + E)$|
|По памяти|$O(V+E)$|$O(V)$|

### Ограничения и плюсы
### Применимость
- маршрутизация в сетях
- оптимизация транспортных маршрутов




-----
## Алгоритм Флойда-Уоршалла 
### Чи шо
### Логика работы
1. инициализация: если есть ребра (i, j), то dist[i][j] = w, если нет ребра, то расстояние = $\infin$, dist[i][i] = 0 для всех i
2. далее используется дп
3. проверка на отрицательные циклы
- __инвариант__  
    после k итераций: матрица расстояний содержит кратчайшие пути, использующие в качестве промежуточных только вершины из множества {0 .. k-1}
    
- __оптимизация:__  
    если не нужно восстанавливать пути, можно использовать одну матрицу (без копирования), ранняя остановка при обнаружении отцательного цикла, использование битовых масок

#### Псевдокод
```
func floyd(w):
    d = ω // изначально d=ω
    for i ∈ V
        for u ∈ V
            for v ∈ V
                if d[u][i] + d[i][v] < d[u][v]
                    d[u][v] = d[u][i] + d[i][v]
                    next[u][v] = next[u][i]
```

#### Пример кода
```cpp
const int INF = numeric_limits<int>::max(); // Бесконечность

void floydWarshall(vector<vector<int>>& dist, int V) {
    for (int k = 0; k < V; k++) {         // Промежуточная вершина
        for (int i = 0; i < V; i++) {     // Начальная вершина
            for (int j = 0; j < V; j++) { // Конечная вершина
                if (dist[i][k] != INF && dist[k][j] != INF) { // Проверка на бесконечность
                    dist[i][j] = min(dist[i][j], dist[i][k] + dist[k][j]);
                }
            }
        }
    }
}
```
### Используемые структуры данных
- матрица смежности
- матрица предков (для восстановления путей)
- 3D—массив (в динамической версии)
### Асиптотика
|          |Флойд-Уоршалл|
|----------|--------------------|
|По времени|$O(V^3)$|
|По памяти|$O(V^2)$|

### Ограничения и плюсы
### Применимость
- анализ транспортных сетей
- маршрутизация
- обработка графов с отрицательными весами (без циклов)



-----
## Поиск диаметра дерева 
### Чи шо
### Логика работы
1. первый DFS/BFS: запускаем из произвольной вершины, находим самую удаленную вершину
2. второй DFS/BFS: запускаем уже из удаленной вершины, находим самую удаленную вершину для этой. расстояние между ними - это диаметр дерева
- __инвариант__
    - после первого поиска гарантированно найдется вершина Х, которая лежит на одном из концов диаметра
- __оптимизация__: для больших деревьев использовать BFS или разбиение на под-деревья, поиск центра дерева и исходить уже от него

#### Псевдокод
```
int diameterTree(list<list<int>> g):        
    v = u = w = 0
    d = bfs(g, v)
    for i = 0, i < n, i++
         if d[i] > d[u]
              u = i
    d = bfs(g, u)
    for i = 0, i < n, i++
          if d[i] > d[w]
               w = i
    return d[w]
```
#### Пример кода
```cpp
pair<int, int> bfs(int start, int V) {
    dist.assign(V, -1);
    queue<int> q;
    q.push(start);
    dist[start] = 0;
    
    int farthestNode = start;
    
    while (!q.empty()) {
        int node = q.front();
        q.pop();
        
        for (int neighbor : tree[node]) {
            if (dist[neighbor] == -1) { // Если ещё не посещали
                dist[neighbor] = dist[node] + 1;
                q.push(neighbor);
                farthestNode = neighbor;
            }
        }
    }
    
    return {farthestNode, dist[farthestNode]};
}

int findTreeDiameter(int V) {
    // Первый BFS от произвольной вершины (например, 0)
    int nodeX = bfs(0, V).first;
    
    // Второй BFS от самой удалённой вершины
    int diameter = bfs(nodeX, V).second;
    
    return diameter;
}
```

### Используемые структуры данных
- список смежности
- очередь для BFS или стек для DFS
- массив расстояний
### Асиптотика
|          |Поиск диаметра|
|----------|----------------|
|По времени|$O(V)$|
|По памяти|$O(V)$|

### Ограничения и плюсы
### Применимость
- компьютерные сети
- оптимизация маршрутов




------
## Алгоритм Куна для поиска макс парсоч в двудольном графе 
### Чи шо
### Логика работы
1. начинаем с пустого множества ребер
2. запускаем DFS из каждой вершины левой доли
3. ищем аугментирующий путь (путь, увеличивающий паросочетание)
4. переназначаем ребра, если нашли путь
5. повторяем, пока паросочетание увеличивается
- __инвариант__  
    на каждой итерации паросочетание либо остаётся прежним, либо увеличивается, а алгоритм гарантированно завершится через V итераций
    
- __оптимизация__  
    жадная инициализация (предварительно находим тривиальные пары, битовые маски

#### Псевдокод

```
bool dfs(v: int):
    if (used[v])
        return false
    used[v] = true
    for to in g[v]
        if (matching[to] == -1 or dfs(matching[to])):
            matching[to] = v
            return true 
    return false

function main():
    fill(matching, -1)
    for i = 1..n
         fill(used, false)
         dfs(i)
    for i = 1..n
         if (matching[i] != -1)
              print(i, " ", matching[i])
```
#### Пример кода
```cpp
// DFS для поиска аугментирующего пути
bool dfs(int u) {
    if (visited[u]) return false;
    visited[u] = true;
    
    for (int v : graph[u]) {
        if (match[v] == -1 || dfs(match[v])) {
            match[v] = u; // Назначаем новую пару
            return true;
        }
    }
    
    return false;
}

// Поиск максимального паросочетания
int kunAlgorithm(int leftSize, int rightSize) {
    match.assign(rightSize, -1); // Изначально все вершины правой доли свободны
    int maxMatching = 0;
    
    for (int u = 0; u < leftSize; u++) {
        visited.assign(leftSize, false);
        if (dfs(u)) maxMatching++;
    }
    
    return maxMatching;
}
```
### Используемые структуры данных
- список смежности
- массив совпадений
- массив посещений
### Асиптотика
|          |Кун для паросочетаний|
|----------|----------------|
|По времени|$O(V × E)$|
|По памяти|$O(V)$|

### Ограничения и плюсы
### Применимость
- разделение задач
- компьютерное зрение





------
## Алгоритм Форда-Фалкерсона и Эдмондса-Карпа для поиска макс потока 
### Чи шо
Алгоритм Форда-Фалкерсона

Алгоритм Эдмондса-Карпа — это оптимизированная версия алгоритма Форда-Фалкерсона, где поиск увеличивающих путей всегда осуществляется через BFS (поиск в ширину). Это гарантирует нахождение кратчайшего по количеству рёбер увеличивающего пути на каждом шаге.
### Логика работы
#### Форд-Фалкерсон
1. Находим увеличивающий путь (DFS из источника s в сток t).
2. Определяем бутылочное горлышко — минимальную пропускную способность на пути.
3. Обновляем остаточную сеть:
    - уменьшаем пропускную способность по прямым рёбрам,
    - увеличиваем по обратным (имитируем "обратный" поток).
4. Повторяем, пока есть увеличивающие пути.
- __инвариант__
    - поток остаётся допустимым: для всех вершин, кроме стока и истока выполняется закон сохранения потока, поток через любое ребро не превышает его капасити.
    - остаточная сеть корректно отражает возможности увеличения потока
    - увеличивающий путь всегда улучшает поток

##### Псевдокод
```
int dfs(int u, int flow):         
    if u = t
        return flow
    visited[u] = true                  
    for v in u.children
        auto uv = edge(u, v)
        if not visited[v] and uv.f < uv.c
            int bottleneck = dfs(v, min(Cmin, uv.c - uv.f))
            if bottleneck > 0
                uv.f += bottleneck
                uv.backEdge.f -= bottleneck
                return bottleneck
   return 0
```
##### Пример кода
```cpp
int dfs(int u, int t, int flow) {
    if (u == t) return flow;
    visited[u] = true;
    
    for (int v : adj[u]) {
        if (!visited[v] && capacity[u][v] > 0) { // Если есть ёмкость
            int bottleneck = dfs(v, t, min(flow, capacity[u][v]));
            if (bottleneck > 0) {
                capacity[u][v] -= bottleneck; // Обновляем остаточную сеть
                capacity[v][u] += bottleneck;
                return bottleneck;
            }
        }
    }
    return 0;
}

int maxFlow(int s, int t) {
    int flow = 0, newFlow;
    do {
        visited.assign(V, false);
        newFlow = dfs(s, t, INF);
        flow += newFlow;
    } while (newFlow > 0);
    
    return flow;
}
```

#### Эдмондс-Карп
1. **Инициализация**:
    - Поток на всех рёбрах = 0
    - Построить остаточную сеть
2. **Поиск увеличивающего пути**:
    - Всегда использует BFS для нахождения **кратчайшего пути** в остаточной сети
3. **Обновление потока**:
    - Увеличить поток вдоль найденного пути на минимальную остаточную пропускную способность
4. **Повторять**, пока есть увеличивающие пути  

__инвариант__

На каждом шаге:

- Остаточная сеть корректно отражает доступные пути.
- Текущий поток не нарушает ограничения пропускных способностей.
- Поток в вершине (кроме источника и стока) сбалансирован

*Ключевая теорема*  
Теорема Эдмондса-Карпа:
- Алгоритм выполняет не более $O(V×E)$ увеличений потока
- Каждое увеличение требует $O(E)$ времени (BFS)
- Итоговая сложность: $O(V·E^2)$

##### Псевдокод
```
function EdmondsKarp(G, s, t):
    for (для) каждого ребра (u,v) ∈ E[G]
        f[u,v] ← 0
        f[v,u] ← 0
    while (существует кратчайший путь p из s в t в остаточной сети Gf)
        cf(p) ← min{ cf(u,v) : (u,v) ∈ p}
        for (u,v) ∈ p
            f[u,v] ← f[u,v] + cf(p)
            f[v,u] ← −f[u,v]

```
##### Пример кода
```cpp
int edmondsKarp(vector<vector<int>>& capacity, int source, int sink) {
    int n = capacity.size();
    vector<vector<int>> flow(n, vector<int>(n, 0));
    vector<int> parent(n);
    int max_flow = 0;

    while (true) {
        // BFS для поиска увеличивающего пути
        fill(parent.begin(), parent.end(), -1);
        parent[source] = -2;
        queue<pair<int, int>> q;
        q.push({source, INT_MAX});

        while (!q.empty()) {
            int u = q.front().first;
            int current_flow = q.front().second;
            q.pop();

            for (int v = 0; v < n; v++) {
                if (parent[v] == -1 && capacity[u][v] > flow[u][v]) {
                    parent[v] = u;
                    int new_flow = min(current_flow, capacity[u][v] - flow[u][v]);
                    if (v == sink) {
                        max_flow += new_flow;
                        // Обновляем поток вдоль пути
                        int node = v;
                        while (node != source) {
                            int prev = parent[node];
                            flow[prev][node] += new_flow;
                            flow[node][prev] -= new_flow;
                            node = prev;
                        }
                        break;
                    }
                    q.push({v, new_flow});
                }
            }
        }

        // Если не нашли путь - завершаем
        if (parent[sink] == -1)
            break;
    }

    return max_flow;
}
```
### Используемые структуры данных
- Форд-Фалкерсон
    - матрица смежности
    - список смежности
    - массив посещений
- Эдмондс-Карп
    - матрица смежности
    - список смежности
    - очередь для BFS
    - массив предков
### Асиптотика
|          |Форд-Фалкерсон|Эдмонндс-Карп|
|----------|----------------|------|
|По времени|$O(E × F)$|$O(V × E^2)$|
|По памяти|$O(V + E)$|$O(V^2)$|

*$F$ - значение максимального потока
### Ограничения и плюсы
- при вещественных пропускных способностях алгоритм может не завершиться из-за бесконечной 
- Эдмондс-Карп  
    __*Почему BFS улучшает алгоритм?*__  
    Гарантированная сходимость:
    - BFS всегда находит кратчайший путь
    - Длина кратчайшего пути монотонно возрастает (теорема Эдмондса-Карпа)  
    
    Ограничение числа итераций:
    - Максимум O(V*E) увеличивающих путей
    - Каждый BFS работает за O(E)
### Применимость
- оптимизация потоков
- логистика



-----
## Алгоритм Форда-Фалкерсона для поиска макс парсоч в двудольном графе 
### Чи шо
### Логика работы


#### Шаги преобразования

1. **Создаем сеть потока**:
    - Направляем все ребра от левой доли к правой
    - Добавляем исток с ребрами ко всем вершинам левой доли
    - Добавляем сток со всеми ребрами от правой доли
2. **Пропускные способности**:
    - Все ребра имеют пропускную способность 1
3. **Запускаем Форда-Фалкерсона**:
    - Каждый единичный поток = одно ребро в паросочетании
- __инвариант__
    
    После каждой итерации:

    - Поток остаётся целочисленным (т. к. все пропускные способности = 1).

    - Размер паросочетания не убывает (каждый увеличивающий путь добавляет +1 к паросочетанию).
    
    - В конце алгоритма нет увеличивающих путей → паросочетание максимально.

#### Псевдокод
```
bool dfs(x):
    if vis[x]
        return false
    vis[x] = true
    for (x,y)∈E

        if py[y] == -1
            py[y] = x
            px[x] = y
            return true
        else
            if dfs(py[y])
                py[y] = x
                px[x] = y
                return true
    return false

func fordFulkerson():
    fill(px, -1)
    fill(py, -1)
    isPath = true
    while isPath
        isPath = false
        fill(vis, false)
        for x∈L

            if px[x] == -1
                if dfs(x)
                    isPath = true
```
#### Пример кода
```cpp
bool bfs(const vector<vector<int>>& residual, vector<int>& parent, int source, int sink) {
    fill(parent.begin(), parent.end(), -1);
    queue<int> q;
    q.push(source);
    parent[source] = -2;

    while (!q.empty()) {
        int u = q.front();
        q.pop();

        for (int v = 0; v < residual.size(); ++v) {
            if (parent[v] == -1 && residual[u][v] > 0) {
                parent[v] = u;
                if (v == sink) return true;
                q.push(v);
            }
        }
    }
    return false;
}

int fordFulkerson(vector<vector<int>>& graph, int source, int sink) {
    vector<vector<int>> residual = graph;
    vector<int> parent(graph.size());
    int max_matching = 0;

    while (bfs(residual, parent, source, sink)) {
        int path_flow = INT_MAX;
        for (int v = sink; v != source; v = parent[v]) {
            int u = parent[v];
            path_flow = min(path_flow, residual[u][v]);
        }

        for (int v = sink; v != source; v = parent[v]) {
            int u = parent[v];
            residual[u][v] -= path_flow;
            residual[v][u] += path_flow;
        }

        max_matching += path_flow;
    }

    return max_matching;
}

int maxBipartiteMatching(const vector<vector<int>>& bipartiteGraph, int leftSize) {
    int n = bipartiteGraph.size();
    int source = n, sink = n + 1;
    vector<vector<int>> flowNetwork(n + 2, vector<int>(n + 2, 0));

    // Соединяем исток с левой долей
    for (int u = 0; u < leftSize; ++u) {
        flowNetwork[source][u] = 1;
    }

    // Копируем исходный двудольный граф
    for (int u = 0; u < leftSize; ++u) {
        for (int v : bipartiteGraph[u]) {
            flowNetwork[u][v] = 1;
        }
    }

    // Соединяем правую долю со стоком
    for (int v = leftSize; v < n; ++v) {
        flowNetwork[v][sink] = 1;
    }

    return fordFulkerson(flowNetwork, source, sink);
}
```
### Используемые структуры данных
- список смежности/матрица смежности (хранение графа)
- очередь/стек (для BFS/DFS)
- массивы (родителей, посещенных вершин)
### Асиптотика
|          |Паросочетания|
|----------|-------------|
|По времени|$O(E × F)$|
|По памяти|$O(V + E)$|

*$F$ - размер паросочетания  

**в худшем случае для полных графов по времени: $O(E × V)$
### Ограничения и плюсы
### Применимость
- системы рекомендаций
- распределение ресурсов



-----
## Поиск мостов и точек сочленения
### Чи шо
### Логика работы
Алгоритм основан на **обходе в глубину (DFS)** с подсчётом:

- `tin[v]` — порядковый номер вершины при входе в DFS.
- `low[v]` — минимальный `tin`, достижимый из поддерева `v`.

#### **Поиск мостов**

Ребро `(u → v)` — **мост**, если `low[v] > tin[u]`.

#### **Поиск точек сочленения**

Вершина `u` — **точка сочленения**, если:

1. `u` — корень DFS-дерева **и** имеет ≥ 2 детей.
2. `u` — не корень **и** `low[v] ≥ tin[u]` для какого-то ребра `(u → v)`
- __инвариант:__
    - **После обработки вершины `v`**:
        - `low[v]` хранит минимальное `tin`, достижимое из `v` без использования родительского ребра.
        - Если `low[v] > tin[u]`, то ребро `(u → v)` — мост.
        - Если `low[v] ≥ tin[u]` и `u` не корень, то `u` — точка сочленения.
- __оптимизация__: ранний выход, итеративный DFS, удаление дубликатов
#### обход в глубину для поиск точек соочленения
```
function findCutPoints(G[n]: Graph): // функция принимает граф G с количеством вершин n и выполняет поиск точек сочленения во всем графе 
    visited = array[n, false]
                   
function dfs(v: int, p: int):
    time = time + 1
    low[v] = tin[v] = time 
    visited[v] = true
    count = 0             
    for u: (v, u) in G   
        if u == p
            continue
        if visited[u]
            low[v] = min(low[v], tin[u])
        else
            dfs(u, v) 
            count = count + 1
            low[v] = min(low[v], low[u])
            if p != -1 and low[u] >= tin[v]
                v — cutpoint 
    if p == -1 and count >= 2
        v — cutpoint 
                    
for i = 1 to n             
    if not visited[i]              
        dfs(i, -1)
```
#### Обход в глубину для поиска мостов
```
function dfs(v):
    time = time + 1
    tin[v] = time
    low[v] = time 
    for всех u смежных с v
        if (v, u) — обратное ребро
            low[v] = min(ret[v], tin[u])
        if вершина u — белая
            dfs(u)
            low[v] = min(low[v], low[u]) 
            if low[u] > tin[v] 
                ребро (v, u) — мост
```
### Используемые структуры данных
- список смежности/матрица смежности
- массивы
- стек (для DFS)
### Асиптотика
|          |Поиск мостов и ТС|
|----------|----------------|
|По времени|$O(V + E)$|
|По памяти|$O(V)$|


### Ограничения и плюсы
### Применимость
- анализ надежности сетей
- построение двусвязных компонент (укладка графов)
- задачи на связность



-----
## Жадный алгоритм для поиска раскраски графа
### Чи шо
### Логика работы
1. Выбрать порядок вершин (например, по степени или произвольно).
2. Для каждой вершины:
    - Проверить цвета всех соседей.
    - Назначить минимальный доступный цвет (начиная с 1).
- __инвариант:__
    
    После раскраски каждой вершины никакие два соседа не имеют одинаковый цвет.
    
- __оптимизация:__ сортировка вершин, использование битовых масок

```cpp
vector<vector<int>> graph;  // Список смежности
vector<int> color;          // Цвета вершин (0 — не раскрашена)

void greedyColoring() {
    int V = graph.size();
    color.assign(V, 0);     // Изначально все вершины без цвета

    // Первая вершина — цвет 1
    color[0] = 1;

    for (int v = 1; v < V; ++v) {
        // Множество цветов соседей
        set<int> used_colors;

        // Проверяем всех соседей v
        for (int u : graph[v]) {
            if (color[u] != 0) {
                used_colors.insert(color[u]);
            }
        }

        // Находим минимальный доступный цвет
        int cr = 1;
        while (used_colors.count(cr)) {
            cr++;
        }
        color[v] = cr;
    }
}
```
### Используемые структуры данных
- список смежности/матрица смежности
- массив цветов
- множество/массив использованных цветов у соседей
### Асиптотика
|          |Карась_им|
|----------|----------------|
|По времени|$O(V^2 + E)$|
|По памяти|$O(V + E)$|

### Ограничения и плюсы
### Применимость
- составление расписаний
- регистрация переменных в компиляторах
- задачи на картах


